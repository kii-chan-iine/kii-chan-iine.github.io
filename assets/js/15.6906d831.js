(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{626:function(t,a,s){"use strict";s.r(a);var n=s(2),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("Boxx",{attrs:{changeTime:"10000"}}),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"title"},[t._v("前言")]),s("p",[t._v("这里主要讲深度学习的一些基础知识。")])]),t._v(" "),s("h1",{attrs:{id:"深度学习的思考"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#深度学习的思考"}},[t._v("#")]),t._v(" 深度学习的思考")]),t._v(" "),s("p",[t._v("在VGG中，卷积网络达到了19层，在GoogLeNet中，网络史无前例的达到了22层。那么，网络的精度会随着网络的层数增多而增多吗？在深度学习中，网络层数增多一般会伴着下面几个问题")]),t._v(" "),s("ol",[s("li",[t._v("计算资源的消耗")]),t._v(" "),s("li",[t._v("模型容易过拟合")]),t._v(" "),s("li",[t._v("梯度消失/梯度爆炸问题的产生")])]),t._v(" "),s("p",[t._v("问题1可以通过GPU集群来解决，对于一个企业资源并不是很大的问题；问题2的过拟合通过采集海量数据，并配合Dropout正则化等方法也可以有效避免；问题3通过Batch Normalization也可以避免。貌似我们只要无脑的增加网络的层数，我们就能从此获益，但实验数据给了我们当头一棒。")]),t._v(" "),s("h1",{attrs:{id:"收敛性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#收敛性"}},[t._v("#")]),t._v(" 收敛性")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("数据库太小一般不会带来不收敛的问题，只要你一直在train总会收敛（rp问题跑飞了不算）。"),s("strong",[t._v("反而不收敛一般是由于样本的信息量太大导致网络不足以fit住整个样本空间")]),t._v("。"),s("strong",[t._v("样本少只可能带来过拟合的问题")]),t._v("，你看下你的training set上的loss收敛了吗？如果只是validate set上不收敛那就说明overfitting了，这时候就要考虑各种anti-overfit的trick了，比如dropout，SGD，增大minibatch的数量，减少fc层的节点数量，momentum，finetune等。")])]),t._v(" "),s("li",[s("p",[t._v(".learning rate设大了会带来跑飞（loss突然一直很大）的问题，这个是新手最常见的情况——为啥网络跑着跑着看着要收敛了结果突然飞了呢？"),s("strong",[t._v("可能性最大的原因是你用了relu作为激活函数的同时使用了softmax或者带有exp的函数做分类层的loss函数")]),t._v("。当某一次训练传到最后一层的时候，某一节点激活过度（比如100），那么exp(100)=Inf，发生溢出，bp后所有的weight会变成NAN，然后从此之后weight就会一直保持NAN，于是loss就飞起来啦。在做GNN实验的时候，经常遇到准确率突然下降的情况，自己也发现不了原因，因为准确率一直不错，索性就一直保留着这个为题，如图，可以看到期间一共跑飞过两次，因为学习率设的并不是非常大所以又拉了回来。如果lr设的过大会出现跑飞再也回不来的情况。这时候你停一下随便挑一个层的weights看一看，很有可能都是NAN了。对于这种情况建议用二分法尝试。0.1~0.0001.不同模型不同任务最优的lr都不一样。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20190603225532802.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTQ3OTEwOA==,size_16,color_FFFFFF,t_70",alt:"https://img-blog.csdnimg.cn/20190603225532802.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTQ3OTEwOA==,size_16,color_FFFFFF,t_70"}})])]),t._v(" "),s("li",[s("p",[t._v("尽量收集更多的数据。有个方法是爬flickr，找名人标签，然后稍微人工剔除一下就能收集一套不错的样本。其实收集样本不在于多而在于hard，比如你收集了40张基本姿态表情相同的同一个人的图片不如收集他的10张不同表情的图片。之前做过试验，50张variance大的图per person和300多张类似的图per person训练出来的模型后者就比前者高半个点。")])]),t._v(" "),s("li",[s("p",[t._v("尽量用小模型。如果"),s("strong",[t._v("数据太少尽量缩小模型复杂度")]),t._v("。考虑减少层数或者减少"),s("strong",[t._v("kernel numbe")]),t._v("r。")])])]),t._v(" "),s("h1",{attrs:{id:"bn层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bn层"}},[t._v("#")]),t._v(" BN层")]),t._v(" "),s("p",[t._v("为什么提出BN？")]),t._v(" "),s("p",[t._v("深度网络在采用Mini-Batch SGD训练的过程中，隐藏层激活函数的输入分布变化大，导致模型收敛慢。")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://www.zhihu.com/equation?tex=%5Ctilde%7Bx%7D%3D%5Cgamma%5Cfrac%7Bx-%5Cmu%7D%7B%5Csqrt%7B%5Csigma%5E%7B2%7D-%5Cvarepsilon%7D%7D%2B%5Cbeta%5C%5C",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.zhihu.com/equation?tex=%5Ctilde%7Bx%7D%3D%5Cgamma%5Cfrac%7Bx-%5Cmu%7D%7B%5Csqrt%7B%5Csigma%5E%7B2%7D-%5Cvarepsilon%7D%7D%2B%5Cbeta%5C%5C"),s("OutboundLink")],1)]),t._v(" "),s("p",[s("strong",[t._v("Batch Normalization参数的形状?")])]),t._v(" "),s("p",[t._v("对feature map的channel方向求均值和方差, 假设feature map.shape=(b,c,w,h)，那么均值和方差的形状为( 1 , c , 1 , 1)，")]),t._v(" "),s("p",[t._v("和")]),t._v(" "),s("p",[t._v("的形状分别也是( 1 , c , 1 , 1)，因此于一层BN层可学习的参数数量为2c。")]),t._v(" "),s("p",[s("strong",[t._v("Batch Normalization的好处")])]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("解决了Internal Covariate Shift的问题")]),t._v("：前人采用"),s("strong",[t._v("很小的学习率/非常小心的权重初始化")]),t._v("来解决Internal Covariate Shift的问题，BN解决了Internal Covariate Shift问题之后，就可以采用较大的学习率，能更快收敛")]),t._v(" "),s("li",[t._v("BN减轻了梯度消失，梯度爆炸问题："),s("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//blog.csdn.net/ygfrancois/article/details/90382459",target:"_blank",rel:"noopener noreferrer"}},[t._v("详见"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("BN可支持更多的激活函数")]),t._v(" "),s("li",[t._v("BN一定程度上增加了泛化能力，dropout等技术可以去掉。")])]),t._v(" "),s("h1",{attrs:{id:"resnet"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resnet"}},[t._v("#")]),t._v(" Resnet")]),t._v(" "),s("p",[t._v("一般情况下，模型退化主要有以下几种原因：")]),t._v(" "),s("ul",[s("li",[t._v("过拟合，层数越多，参数越复杂，泛化能力弱")]),t._v(" "),s("li",[t._v("梯度消失/梯度爆炸，层数过多，梯度反向传播时由于链式求导连乘使得梯度过大或者过小，使得梯度出现消失/爆炸，对于这种情况，可以通过BN(batch normalization)可以解决")]),t._v(" "),s("li",[t._v("由深度网络带来的退化问题，一般情况下，网络层数越深越容易学到一些复杂特征，理论上模型效果越好，但是由于深层网络中含有大量非线性变化，每次变化相当于丢失了特征的一些原始信息，从而导致层数越深退化现象越严重。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled.png",alt:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled.png"}})]),t._v(" "),s("p",[t._v("残差块的计算方式为：$F ( x ) = W 2 ⋅ r e l u ( W 1 x )$ \n残差块的输出为:    $r e l u ( H ( x ) ) = r e l u ( F ( x ) + x )$")]),t._v(" "),s("p",[s("strong",[t._v("残差块误差优化：")]),t._v(" 残差网络通过加入 shortcut connections（或称为 skip connections），变得更加容易被优化。在不用skip连接之前，假设输入是x ，最优输出是x，此时的优化目标是预测输出H ( x ) = x ，加入skip连接后，优化输出H ( x ) 与输入x 的差别，即为残差F ( x ) = H ( x ) − x，此时的优化目标是F(x)的输出值为0。后者会比前者更容易优化。\n"),s("strong",[t._v("用残差更容易优化")]),t._v("：引入残差后的映射对输出的变化更敏感。设$H_{1}(x)$是加入skip连接前的网络映射$H_{2}(x)$是加入skip连接的网络映射。对于输入x = 5，设此时$H_{1}(5)=5.1,H_2(x)=5.1$,那么$H_{2}(5)=F(5)+5,F(5)=0.1$。当输出变为5.2时，F(x)由0.1变为0.2，明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化。\n简单的加法不会给网络增加额外的参数和计算量，同时可以大大增加模型的训练速度，提高训练效果。并且当模型的层数加深时，能够有效地解决退化问题。\n"),s("strong",[t._v("残差网络为什么是有效的")]),t._v("：对于大型的网络，无论把残差块添加到神经网络的中间还是末端，都不会影响网络的表现。因为可以给残差快中的weight设置很大的L2正则化水平，使得$F(x)=0$，这样使得加入残差块至少不会使得网络变差，此时的残块等价于恒等映射。若此时残差块中的weight学到了有用的信息，那就会比恒等映射更好，对网络的性能有帮助。\n总结： ResNet有很多旁路支线可以将输入直接连到后面的层，使得后面的层可以直接学习残差，简化了学习难度。传统的卷积层和全连接层在信息传递时，或多或少会存在信息丢失，损耗等问题。"),s("strong",[t._v("ResNet将输入信息绕道传到输出，保护了信息的完整性.")])]),t._v(" "),s("h1",{attrs:{id:"nn-sequential"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-sequential"}},[t._v("#")]),t._v(" nn.Sequential")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# hyper parameters")]),t._v("\nin_dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nn_hidden_1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nn_hidden_2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nout_dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Net")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" in_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      \tself"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n            nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_hidden_1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最后一层不需要添加激活函数")]),t._v("\n            nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_hidden_2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  \t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      \tx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      \t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#其实这个Sequential就是相当于把里面的东西打包了，将网络层和激活函数结合起来。")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br")])]),s("h1",{attrs:{id:"激活函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#激活函数"}},[t._v("#")]),t._v(" 激活函数")]),t._v(" "),s("p",[t._v("激活函数（relu，prelu，elu，+BN）对比on cifar10")]),t._v(" "),s("p",[t._v("可参考上一篇：")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://www.cnblogs.com/jins-note/p/9646602.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("激活函数 ReLU、LReLU、PReLU、CReLU、ELU、SELU  的定义和区别"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("一．理论基础")]),t._v(" "),s("p",[t._v("1.1激活函数")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150404043-1209381965.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150404043-1209381965.png"}})]),t._v(" "),s("p",[t._v("1.2 elu论文（FAST AND ACCURATE DEEP NETWORK LEARNING BY")]),t._v(" "),s("p",[t._v("EXPONENTIAL LINEAR UNITS (ELUS)）")]),t._v(" "),s("p",[t._v("1.2.1 摘要")]),t._v(" "),s("p",[t._v("论文中提到，elu函数可以加速训练并且可以提高分类的准确率。它有以下特征：")]),t._v(" "),s("p",[t._v("1）elu由于其正值特性，可以像relu,lrelu,prelu一样缓解梯度消失的问题。")]),t._v(" "),s("p",[t._v("2）相比relu，elu存在负值，可以将激活单元的输出均值往0推近，达到")]),t._v(" "),s("p",[t._v("batchnormlization的效果且减少了计算量。（输出均值接近0可以减少偏移效应进而使梯")]),t._v(" "),s("p",[t._v("度接近于自然梯度。）")]),t._v(" "),s("p",[t._v("3）Lrelu和prelu虽然有负值存在，但是不能确保是一个噪声稳定的去激活状态。")]),t._v(" "),s("p",[t._v("4）Elu在负值时是一个指数函数，对于输入特征只定性不定量。")]),t._v(" "),s("p",[t._v("1.2.2.bias shift correction speeds up learning")]),t._v(" "),s("p",[t._v("为了减少不必要的偏移移位效应，做出如下改变：（i）输入单元的激活可以")]),t._v(" "),s("p",[t._v("以零为中心，或（ii）可以使用具有负值的激活函数。 我们介绍一个新的")]),t._v(" "),s("p",[t._v("激活函数具有负值，同时保持正参数的特性，即elus。")]),t._v(" "),s("p",[t._v("1.2.4实验")]),t._v(" "),s("p",[t._v("作者把elu函数用于无监督学习中的autoencoder和有监督学习中的卷积神经网络；")]),t._v(" "),s("p",[t._v("elu与relu，lrelu，SReLU做对比实验；数据集选择mnist，cifar10，cifar100.")]),t._v(" "),s("p",[t._v("2ALL-CNN for cifar-10")]),t._v(" "),s("p",[t._v("2.1结构设计")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150412758-258836552.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150412758-258836552.png"}})]),t._v(" "),s("p",[t._v("ALL-CNN结构来自论文（STRIVING FOR SIMPLICITY:")]),t._v(" "),s("p",[t._v("THE ALL CONVOLUTIONAL NET）主要工作是把pool层用stride=2的卷积来代替，提出了一些全卷积网络架构，kernel=3时效果最好，最合适之类的，比较好懂，同时效果也不错，比原始的cnn效果好又没有用到一些比较大的网络结构如resnet等。")]),t._v(" "),s("p",[t._v("附上：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("Lrelu实现：\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("lrelu")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" leak"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lrelu"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("maximum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" leak "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nPrelu实现：\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("parametric_relu")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\nalphas "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'alpha'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ninitializer"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant_initializer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ndtype "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npos "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nneg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" alphas "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("abs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("alphas"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" pos "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" neg\n\nBN实现：\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("batch_norm")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("scope"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bn'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n  Batch normalization on convolutional maps.\n  Args:\n    x: Tensor, 4D BHWD input maps\n    n_out: integer, depth of input maps\n    phase_train: boolean tf.Variable, true indicates training phase\n    scope: string, variable scope\n\n  Return:\n    normed: batch-normalized maps\n  """')]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("variable_scope"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scope"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    beta "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("n_out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'beta'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trainable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    gamma "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("n_out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gamma'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trainable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_to_collection"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'biases'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" beta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_to_collection"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'weights'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gamma"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    batch_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("moments"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'moments'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ema "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ExponentialMovingAverage"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.99")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mean_var_with_update")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      ema_apply_op "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("batch_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("control_dependencies"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ema_apply_op"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n       "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("identity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("identity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#mean, var = control_flow_ops.cond(phase_train,")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mean, var = control_flow_ops.cond(phase_train,")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   mean_var_with_update,")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#   lambda: (ema.average(batch_mean), ema.average(batch_var)))")]),t._v("\n    mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean_var_with_update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    normed "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_normalization"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      beta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gamma"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" normed\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br")])]),s("p",[t._v("在cifar10 上测试结果如下：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150502254-1055081325.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150502254-1055081325.png"}})]),t._v(" "),s("p",[t._v("以loss所有结果如下：relu+bn>elu>prelu>elubn>relu")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150510382-1875945396.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150510382-1875945396.png"}})]),t._v(" "),s("p",[t._v("所有的测试准确率如下")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150517165-1710089123.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150517165-1710089123.png"}})]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150525985-582258259.png",alt:"https://img2018.cnblogs.com/blog/1470684/201809/1470684-20180914150525985-582258259.png"}})]),t._v(" "),s("p",[t._v("relu+bn组合准确率最高，relu+bn>elu>prelu>elubn>relu")]),t._v(" "),s("p",[t._v("可见elu在激活函数里表现最好，但是它不必加BN，这样减少了BN的计算量。")]),t._v(" "),s("p",[t._v("3.ALL-CNN for cifar-100")]),t._v(" "),s("p",[t._v("cifar100数据集")]),t._v(" "),s("p",[t._v("CIFAR-100 python version,下载完之后解压，在cifar-100-python下会出现：meta,test和train")]),t._v(" "),s("p",[t._v("三个文件，他们都是python用cPickle封装的pickled对象")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("解压：tar -zxvf xxx.tar.gz\ncifar-100-python/\ncifar-100-python/file.txt~\ncifar-100-python/train\ncifar-100-python/test\ncifar-100-python/meta\ndef unpickle(file):\nimport cPickle\nfo = open(file, ‘rb’)\ndict = cPickle.load(fo)\nfo.close()\nreturn dict\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br")])]),s("p",[t._v("通过以上代码可以将其转换成一个dict对象，test和train的dict中包含以下元素：")]),t._v(" "),s("p",[t._v("data——一个nx3072的numpy数组,每一行都是(32,32,3)的RGB图像,n代表图像个数")]),t._v(" "),s("p",[t._v("coarse_labels——一个范围在0-19的包含n个元素的列表,对应图像的大类别")]),t._v(" "),s("p",[t._v("fine_labels——一个范围在0-99的包含n个元素的列表,对应图像的小类别")]),t._v(" "),s("p",[t._v("而meta的dict中只包含fine_label_names,第i个元素对应其真正的类别。")]),t._v(" "),s("p",[t._v("二进制版本（我用的）：")]),t._v(" "),s("p",[t._v("<1 x coarse label><1 x fine label><3072 x pixel>")]),t._v(" "),s("p",[t._v("…")]),t._v(" "),s("p",[t._v("<1 x coarse label><1 x fine label><3072 x pixel>")]),t._v(" "),s("p",[t._v("网络结构直接在cifar10的基础上输出100类即可，只对cifar100的精细标签100个进行分类任务，因此代码里取输入数据集第二个值做为标签。（tensorflow的cifar10代码）")]),t._v(" "),s("p",[s("code",[t._v("label_bytes =2 # 2 for CIFAR-100 #取第二个标签100维 result.label = tf.cast( tf.strided_slice(record_bytes, [1], [label_bytes]), tf.int32)")])]),t._v(" "),s("p",[t._v("在all CNN 9层上，大约50k步，relu+bn组合测试的cifar100 test error为0.36")]),t._v(" "),s("p",[t._v("PS:")]),t._v(" "),s("p",[t._v("Activation Function Cheetsheet")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img2018.cnblogs.com/blog/1470684/201811/1470684-20181107220712431-1920470308.png",alt:"https://img2018.cnblogs.com/blog/1470684/201811/1470684-20181107220712431-1920470308.png"}})]),t._v(" "),s("h1",{attrs:{id:"层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#层"}},[t._v("#")]),t._v(" 层")]),t._v(" "),s("ol",[s("li",[t._v("Linear:线性层，最原始的称谓，单层即无隐层。熟悉torch的同学都清楚torch.nn.Linear就是提供了一个in_dim * out_dim的tensor layer而已。")]),t._v(" "),s("li",[t._v("Dense：密集层，可以指单层linear也可以指多层堆叠，可无隐层也可有但一般多指后者。熟悉keras的同学也知道dense层其实就是多层线性层的堆叠。(pytorch中的是不是没有，而是Linear？)")]),t._v(" "),s("li",[t._v("MLP：多层感知器（Multi-layer perceptron neural networks），指多层linear的堆叠，有隐层。")]),t._v(" "),s("li",[t._v("FC：全连接层(fully connected layer)，单层多层均可以表示，是对Linear Classifier最笼统的一种称谓。")])]),t._v(" "),s("h1",{attrs:{id:"评价指标"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#评价指标"}},[t._v("#")]),t._v(" 评价指标")]),t._v(" "),s("p",[t._v("写文章时候可以选用一下几个\n1、均方误差：MSE（Mean Squared Error）\n2、均方根误差：RMSE（Root Mean Squard Error）RMSE=sqrt（MSE）。\n3、平均绝对误差：MAE（Mean Absolute Error）\n4、决定系数：R2（R-Square）\n一般来说，R-Squared 越大，表示模型拟合效果越好。R-Squared 反映的是大概有多准，因为，随着样本数量的增加，R-Square必然增加，无法真正定量说明准确程度，只能大概定量。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" mean_squared_error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("mean_absolute_error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("r2_score\n\nmse "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean_squared_error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("testPredict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrmse "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mean_squared_error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("testPredict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmae "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean_absolute_error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("testPredict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nr2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" r2_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("testPredict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])]),s("p",[t._v("MAPE需要自己编写")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mape")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_pred"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("abs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_pred "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" y_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" y_true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("testPredict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("testY"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("h1",{attrs:{id:"损失函数和优化器"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#损失函数和优化器"}},[t._v("#")]),t._v(" 损失函数和优化器")]),t._v(" "),s("h2",{attrs:{id:"损失函数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[t._v("#")]),t._v(" 损失函数")]),t._v(" "),s("p",[t._v("损失函数，又叫目标函数，是编译一个神经网络模型必须的两个参数之一。另一个必不可少的参数是优化器。")]),t._v(" "),s("p",[t._v("损失函数是指用于计算标签值和预测值之间差异的函数，在机器学习过程中，有多种损失函数可供选择，典型的有距离向量，绝对值向量等。")]),t._v(" "),s("p",[s("img",{attrs:{src:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%201.png",alt:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%201.png"}})]),t._v(" "),s("p",[t._v("上图是一个用来模拟线性方程自动学习的示意图。粗线是真实的线性方程，虚线是迭代过程的示意，w1 是第一次迭代的权重，w2 是第二次迭代的权重，w3 是第三次迭代的权重。随着迭代次数的增加，我们的目标是使得 wn 无限接近真实值。")]),t._v(" "),s("p",[t._v("那么怎么让 w 无限接近真实值呢？其实这就是损失函数和优化器的作用了。图中 1/2/3 这三个标签分别是 3 次迭代过程中预测 Y 值和真实 Y 值之间的差值（这里差值就是损失函数的意思了，当然了，实际应用中存在多种差值计算的公式），这里的差值示意图上是用绝对差来表示的，那么在多维空间时还有平方差，均方差等多种不同的距离计算公式，也就是损失函数了，这么一说是不是容易理解了呢？")]),t._v(" "),s("p",[t._v("这里示意的是一维度方程的情况，那么发挥一下想象力，扩展到多维度，是不是就是深度学习的本质了？")]),t._v(" "),s("p",[t._v("下面介绍几种常见的损失函数的计算方法，pytorch 中定义了很多类型的预定义损失函数，需要用到的时候再学习其公式也不迟。")]),t._v(" "),s("p",[t._v("我们先定义两个二维数组，然后用不同的损失函数计算其损失值。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autograd "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Variable\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" nn\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("functional "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" F\nsample "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ones"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\ntarget "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Variable "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br")])]),s("p",[t._v("sample 的值为：[[1,1],[1,1]]。")]),t._v(" "),s("p",[t._v("target 的值为：[[0,1],[2,3]]。")]),t._v(" "),s("h3",{attrs:{id:"nn-l1loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-l1loss"}},[t._v("#")]),t._v(" nn.L1Loss")]),t._v(" "),s("p",[s("img",{attrs:{src:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%202.png",alt:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%202.png"}})]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("L1Loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("最后结果是：1。")]),t._v(" "),s("p",[t._v("它的计算逻辑是这样的：")]),t._v(" "),s("ul",[s("li",[t._v("先计算绝对差总和：|0-1|+|1-1|+|2-1|+|3-1|=4；")])]),t._v(" "),s("h3",{attrs:{id:"nn-smoothl1loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-smoothl1loss"}},[t._v("#")]),t._v(" nn.SmoothL1Loss")]),t._v(" "),s("p",[s("img",{attrs:{src:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%203.png",alt:"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E8%80%83%20b7cca7604a46493bb8be335c2b5b92d0/Untitled%203.png"}})]),t._v(" "),s("p",[t._v("SmoothL1Loss 也叫作 Huber Loss，误差在 (-1,1) 上是平方损失，其他情况是 L1 损失。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SmoothL1Loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n最后结果是："),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.625")]),t._v("。\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("h3",{attrs:{id:"nn-mseloss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-mseloss"}},[t._v("#")]),t._v(" nn.MSELoss")]),t._v(" "),s("p",[t._v("平方损失函数。其计算公式是预测值和真实值之间的平方和的平均数。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MSELoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n最后结果是："),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),t._v("。\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("h3",{attrs:{id:"nn-bceloss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-bceloss"}},[t._v("#")]),t._v(" nn.BCELoss")]),t._v(" "),s("p",[t._v("二分类用的交叉熵，其计算公式较复杂，这里主要是有个概念即可，一般情况下不会用到。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BCELoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n最后结果是："),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("13.8155")]),t._v("。\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("h3",{attrs:{id:"nn-crossentropyloss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-crossentropyloss"}},[t._v("#")]),t._v(" nn.CrossEntropyLoss")]),t._v(" "),s("p",[t._v("交叉熵损失函数")]),t._v(" "),s("p",[t._v("该公式用的也较多，比如在图像分类神经网络模型中就常常用到该公式。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CrossEntropyLoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n最后结果是：报错，看来不能直接这么用！\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("看文档我们知道 nn.CrossEntropyLoss 损失函数是用于图像识别验证的，对输入参数有各式要求，这里有这个概念就可以了，在图像识别一文中会有正确的使用方法。")]),t._v(" "),s("h3",{attrs:{id:"nn-nllloss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-nllloss"}},[t._v("#")]),t._v(" nn.NLLLoss")]),t._v(" "),s("p",[t._v("负对数似然损失函数（Negative Log Likelihood）")]),t._v(" "),s("p",[t._v("在前面接上一个 LogSoftMax 层就等价于交叉熵损失了。注意这里的 xlabel 和上个交叉熵损失里的不一样，这里是经过 log 运算后的数值。这个损失函数一般也是用在图像识别模型上。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nll_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nll_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n最后结果会报错！\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("p",[t._v("Nn.NLLLoss 和 nn.CrossEntropyLoss 的功能是非常相似的！通常都是用在多分类模型中，实际应用中我们一般用 NLLLoss 比较多。")]),t._v(" "),s("h3",{attrs:{id:"nn-nllloss2d"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nn-nllloss2d"}},[t._v("#")]),t._v(" nn.NLLLoss2d")]),t._v(" "),s("p",[t._v("和上面类似，但是多了几个维度，一般用在图片上。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("N"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" C"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" H"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("N"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" H"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("比如用全卷积网络做分类时，最后图片的每个点都会预测一个类别标签。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NLLLoss2d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n同样结果报错！\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("h2",{attrs:{id:"优化器optim"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#优化器optim"}},[t._v("#")]),t._v(" 优化器Optim")]),t._v(" "),s("p",[t._v("所有的优化函数都位于torch.optim包下，常用的优化器有：SGD,Adam,Adadelta,Adagrad,Adamax等，下面就各优化器分析。")]),t._v(" "),s("h3",{attrs:{id:"使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用"}},[t._v("#")]),t._v(" 使用")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("optimizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\noptimizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0001")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("lr：学习率，大于0的浮点数\nmomentum:动量参数，大于0的浮点数\nparameters：Variable参数，要优化的对象")]),t._v(" "),s("h3",{attrs:{id:"基类-optimizer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基类-optimizer"}},[t._v("#")]),t._v(" 基类 Optimizer")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" defaults"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) —— Variable 或者 dict的iterable。指定了什么参数应当被优化。\ndefaults —— (dict)：包含了优化选项默认值的字典（一个参数组没有指定的参数选项将会使用默认值）。")]),t._v(" "),s("h3",{attrs:{id:"方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#方法"}},[t._v("#")]),t._v(" 方法：")]),t._v(" "),s("ul",[s("li",[t._v("load_state_dict(state_dict)：加载optimizer状态。")]),t._v(" "),s("li",[t._v("state_dict()：以dict返回optimizer的状态。包含两项：state - 一个保存了当前优化状态的dict，param_groups - 一个包含了全部参数组的dict。")]),t._v(" "),s("li",[t._v("add_param_group(param_group)：给 optimizer 管理的参数组中增加一组参数，可为该组参数定制 lr,momentum, weight_decay 等，在 finetune 中常用。")]),t._v(" "),s("li",[t._v("step(closure) ：进行单次优化 (参数更新)。")]),t._v(" "),s("li",[t._v("zero_grad() ：清空所有被优化过的Variable的梯度。")])]),t._v(" "),s("h2",{attrs:{id:"优化算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#优化算法"}},[t._v("#")]),t._v(" 优化算法")]),t._v(" "),s("h3",{attrs:{id:"随机梯度下降算法-sgd算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#随机梯度下降算法-sgd算法"}},[t._v("#")]),t._v(" 随机梯度下降算法 SGD算法")]),t._v(" "),s("p",[t._v("SGD就是每一次迭代计算mini-batch的梯度，然后对参数进行更新，是最常见的优化方法了。即：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dampening"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nesterov"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) ：待优化参数的iterable或者是定义了参数组的dict\nlr (float) ：学习率\nmomentum (float, 可选) ：动量因子（默认：0）\nweight_decay (float, 可选) ：权重衰减（L2惩罚）（默认：0）\ndampening (float, 可选) :动量的抑制因子（默认：0）\nnesterov (bool, 可选) :使用Nesterov动量（默认：False）\n可实现 SGD 优化算法，带动量 SGD 优化算法，带 NAG(Nesterov accelerated gradient)动量 SGD 优化算法,并且均可拥有 weight_decay 项。")]),t._v(" "),s("p",[t._v("对于训练数据集，我们首先将其分成n个batch，每个batch包含m个样本。我们每次更新都利用一个batch的数据，而非整个数据集。这样做使得训练数据太大时，利用整个数据集更新往往时间上不现实。batch的方法可以减少机器的压力，并且可以快速收敛。\n当训练集有冗余时，batch方法收敛更快。\n优缺点：\nSGD完全依赖于当前batch的梯度，所以η可理解为允许当前batch的梯度多大程度影响参数更新。对所有的参数更新使用同样的learning rate，选择合适的learning rate比较困难，容易收敛到局部最优。")]),t._v(" "),s("h3",{attrs:{id:"平均随机梯度下降算法-asgd算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#平均随机梯度下降算法-asgd算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("平均随机梯度下降算法 ASGD算法")])]),t._v(" "),s("p",[t._v("ASGD 就是用空间换时间的一种 SGD。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ASGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lambd"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0001")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" alpha"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.75")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t0"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000000.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) ：待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) ： 学习率（默认：1e-2）\nlambd (float, 可选) ：衰减项（默认：1e-4）\nalpha (float, 可选) ：eta更新的指数（默认：0.75）\nt0 (float, 可选) ：指明在哪一次开始平均化（默认：1e6）\nweight_decay (float, 可选) ：权重衰减（L2惩罚）（默认: 0）")]),t._v(" "),s("h3",{attrs:{id:"adagrad算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#adagrad算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("Adagrad算法")])]),t._v(" "),s("p",[t._v("AdaGrad算法就是将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新。")]),t._v(" "),s("p",[t._v("其中，r为梯度累积变量，r的初始值为0。ε为全局学习率，需要自己设置。δ为小常数，为了数值稳定大约设置为10^-7 。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adagrad"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) ：待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) ：学习率（默认: 1e-2）\nlr_decay (float, 可选) ：学习率衰减（默认: 0）\nweight_decay (float, 可选) ： 权重衰减（L2惩罚）（默认: 0）\n优缺点：\nAdagrad 是一种自适应优化方法，是自适应的为各个参数分配不同的学习率。这个学习率的变化，会受到梯度的大小和迭代次数的影响。梯度越大，学习率越小；梯度越小，学习率越大。缺点是训练后期，学习率过小，因为 Adagrad 累加之前所有的梯度平方作为分母。随着算法不断迭代，r会越来越大，整体的学习率会越来越小。所以，一般来说AdaGrad算法一开始是激励收敛，到了后面就慢慢变成惩罚收敛，速度越来越慢。在深度学习算法中，深度过深会造成训练提早结束。")]),t._v(" "),s("h3",{attrs:{id:"自适应学习率调整-adadelta算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自适应学习率调整-adadelta算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("自适应学习率调整 Adadelta算法")])]),t._v(" "),s("p",[t._v("Adadelta是对Adagrad的扩展，主要针对三个问题：")]),t._v(" "),s("p",[t._v("学习率后期非常小的问题；\n手工设置初始学习率；\n更新xt时，两边单位不统一\n针对以上的三个问题，Adadelta提出新的Adag解决方法。Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adadelta"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rho"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) ：待优化参数的iterable或者是定义了参数组的dict\nrho (float, 可选) ： 用于计算平方梯度的运行平均值的系数（默认：0.9）\neps (float, 可选)： 为了增加数值计算的稳定性而加到分母里的项（默认：1e-6）\nlr (float, 可选)： 在delta被应用到参数更新之前对它缩放的系数（默认：1.0）\nweight_decay (float, 可选) ：权重衰减（L2惩罚）（默认: 0）\n优缺点：\nAdadelta已经不依赖于全局学习率。训练初中期，加速效果不错，很快，训练后期，反复在局部最小值附近抖动。")]),t._v(" "),s("h3",{attrs:{id:"rmsprop算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rmsprop算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("RMSprop算法")])]),t._v(" "),s("p",[t._v("RMSprop 和 Adadelta 一样，也是对 Adagrad 的一种改进。 RMSprop 采用均方根作为分\n母，可缓解 Adagrad 学习率下降较快的问题， 并且引入均方根，可以减少摆动。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RMSprop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" alpha"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.99")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("08")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" centered"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) ：待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) ：学习率（默认：1e-2）\nmomentum (float, 可选) : 动量因子（默认：0）\nalpha (float, 可选) : 平滑常数（默认：0.99）\neps (float, 可选) : 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）\ncentered (bool, 可选):如果为True，计算中心化的RMSProp，并且用它的方差预测值对梯度进行归一化\nweight_decay (float, 可选)：权重衰减（L2惩罚）（默认: 0）")]),t._v(" "),s("h3",{attrs:{id:"自适应矩估计-adam算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自适应矩估计-adam算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("自适应矩估计 Adam算法")])]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.001")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" betas"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.999")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("08")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) – 学习率（默认：1e-3）\nbetas (Tuple[float, float], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999）\neps (float, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）\nweight_decay (float, 可选) – 权重衰减（L2惩罚）（默认: 0）\n优缺点：\nAdam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。\nAdam结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点。")]),t._v(" "),s("ul",[s("li",[t._v("计算效率高")]),t._v(" "),s("li",[t._v("很少的内存需求")]),t._v(" "),s("li",[t._v("梯度的对角线重缩放不变（这意味着亚当将梯度乘以仅带正因子的对角矩阵是不变的，以便更好地理解此堆栈交换）")]),t._v(" "),s("li",[t._v("非常适合数据和/或参数较大的问题")]),t._v(" "),s("li",[t._v("适用于非固定目标")]),t._v(" "),s("li",[t._v("适用于非常嘈杂和/或稀疏梯度的问题")]),t._v(" "),s("li",[t._v("超参数具有直观的解释，通常需要很少的调整（我们将在配置部分中对此进行详细介绍）")])]),t._v(" "),s("h3",{attrs:{id:"adamax算法-adamd的无穷范数变种"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#adamax算法-adamd的无穷范数变种"}},[t._v("#")]),t._v(" "),s("em",[t._v("Adamax算法（Adamd的无穷范数变种）")])]),t._v(" "),s("p",[t._v("Adamax 是对 Adam 增加了一个学习率上限的概念，所以也称之为 Adamax。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adamax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.002")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" betas"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.999")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("08")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) – 学习率（默认：2e-3）\nbetas (Tuple[float, float], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数\neps (float, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）\nweight_decay (float, 可选) – 权重衰减（L2惩罚）（默认: 0）\n优缺点：")]),t._v(" "),s("p",[t._v("Adamax是Adam的一种变体，此方法对学习率的上限提供了一个更简单的范围。\nAdamax学习率的边界范围更简单。")]),t._v(" "),s("h3",{attrs:{id:"sparseadam算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sparseadam算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("SparseAdam算法")])]),t._v(" "),s("p",[t._v("针对稀疏张量的一种“阉割版”Adam 优化方法。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparseAdam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.001")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" betas"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.999")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("08")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) – 学习率（默认：2e-3）\nbetas (Tuple[float, float], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数\neps (float, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）")]),t._v(" "),s("h3",{attrs:{id:"l-bfgs算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#l-bfgs算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("L-BFGS算法")])]),t._v(" "),s("p",[t._v("L-BFGS 属于拟牛顿算法。 L-BFGS 是对 BFGS 的改进，特点就是节省内存。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("LBFGS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_iter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_eval"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \ntolerance_grad"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tolerance_change"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("09")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \nhistory_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" line_search_fn"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("lr (float) – 学习率（默认：1）\nmax_iter (int) – 每一步优化的最大迭代次数（默认：20）)\nmax_eval (int) – 每一步优化的最大函数评价次数（默认：max * 1.25）\ntolerance_grad (float) – 一阶最优的终止容忍度（默认：1e-5）\ntolerance_change (float) – 在函数值/参数变化量上的终止容忍度（默认：1e-9）\nhistory_size (int) – 更新历史的大小（默认：100）")]),t._v(" "),s("h3",{attrs:{id:"弹性反向传播算法-rprop算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#弹性反向传播算法-rprop算法"}},[t._v("#")]),t._v(" "),s("em",[t._v("弹性反向传播算法 Rprop算法")])]),t._v(" "),s("p",[t._v("该优化方法适用于 full-batch，不适用于 mini-batch。不推荐。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Rprop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" etas"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step_sizes"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\nlr (float, 可选) – 学习率（默认：1e-2）\netas (Tuple[float, float], 可选) – 一对（etaminus，etaplis）, 它们分别是乘法的增加和减小的因子（默认：0.5，1.2）\nstep_sizes (Tuple[float, float], 可选) – 允许的一对最小和最大的步长（默认：1e-6，50）\n优缺点：\n该优化方法适用于 full-batch，不适用于 mini-batch。")]),t._v(" "),s("h2",{attrs:{id:"测试集优于训练集的原因"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#测试集优于训练集的原因"}},[t._v("#")]),t._v(" 测试集优于训练集的原因")]),t._v(" "),s("p",[t._v("（1）"),s("strong",[t._v("数据集太小的话，如果数据集切分的不均匀，或者说训练集和测试集的分布不均匀")]),t._v("，如果模型能够正确捕捉到数据内部的分布模式话，这可能造成训练集的内部方差大于验证集，会造成训练集的误差更大。这时你要重新切分数据集或者扩充数据集，使其分布一样")]),t._v(" "),s("p",[t._v("（2）"),s("strong",[t._v("由Dropout造成，它能基本上确保您的测试准确性最好，优于您的训练准确性。Dropout迫使你的神经网络成为一个非常大的弱分类器集合，这就意味着，一个单独的分类器没有太高的分类准确性，只有当你把他们串在一起的时候他们才会变得更强大。")])]),t._v(" "),s("p",[t._v("因为在训练期间，Dropout将这些分类器的随机集合切掉，因此，训练准确率将受到影响。在测试期间，Dropout将自动关闭，并允许使用神经网络中的所有弱分类器，因此，测试精度提高。")]),t._v(" "),s("h1",{attrs:{id:"进度条"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#进度条"}},[t._v("#")]),t._v(" 进度条")]),t._v(" "),s("p",[s("strong",[t._v("一、普通进度条")])]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic2.zhimg.com/80/v2-355c0c9a1b87146041838ec7887a7cad_720w.jpg",alt:"https://pic2.zhimg.com/80/v2-355c0c9a1b87146041838ec7887a7cad_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic2.zhimg.com/v2-f64b41842668306c5fb1da62cfad94ed_b.jpg",alt:"https://pic2.zhimg.com/v2-f64b41842668306c5fb1da62cfad94ed_b.jpg"}})]),t._v(" "),s("p",[s("strong",[t._v("二、带时间的进度条")])]),t._v(" "),s("p",[t._v("导入time模块来计算代码运行的时间，加上代码迭代进度使用格式化字符串来输出代码运行进度")]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic1.zhimg.com/80/v2-b2372d59e028d8a89ba738954a222fc8_720w.jpg",alt:"https://pic1.zhimg.com/80/v2-b2372d59e028d8a89ba738954a222fc8_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic1.zhimg.com/v2-00dd65d19beadddad65a0d3711a07218_b.jpg",alt:"https://pic1.zhimg.com/v2-00dd65d19beadddad65a0d3711a07218_b.jpg"}})]),t._v(" "),s("p",[s("strong",[t._v("三、TPDM 进度条")])]),t._v(" "),s("p",[t._v("这是一个专门生成进度条的工具包，可以使用pip在终端进行下载，当然还能切换进度条风格")]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic3.zhimg.com/80/v2-b38e3414d5253a0dca08e60ed069d356_720w.jpg",alt:"https://pic3.zhimg.com/80/v2-b38e3414d5253a0dca08e60ed069d356_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic3.zhimg.com/v2-42037d2e020ed31268abaa5b10fd0256_b.jpg",alt:"https://pic3.zhimg.com/v2-42037d2e020ed31268abaa5b10fd0256_b.jpg"}})]),t._v(" "),s("p",[s("strong",[t._v("四、progress 进度条")])]),t._v(" "),s("p",[t._v("只需要定义迭代的次数、进度条类型并在每次迭代时告知进度条即可")]),t._v(" "),s("p",[t._v("相关文档："),s("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//pypi.org/project/progress/1.5/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://pypi.org/project/progress/1.5/"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic2.zhimg.com/80/v2-9b08de855fbc6f1e0b5f7a066a3712c1_720w.jpg",alt:"https://pic2.zhimg.com/80/v2-9b08de855fbc6f1e0b5f7a066a3712c1_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic2.zhimg.com/v2-12eebc070634d4f13e6e4febd208efd9_b.jpg",alt:"https://pic2.zhimg.com/v2-12eebc070634d4f13e6e4febd208efd9_b.jpg"}})]),t._v(" "),s("p",[s("strong",[t._v("五、alive_progress 进度条")])]),t._v(" "),s("p",[t._v("顾名思义，这个库可以使得进度条变得生动起来，它比原来我们见过的进度条多了一些动画效果，需要使用pip进行下载")]),t._v(" "),s("p",[t._v("相关文档："),s("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//github.com/rsalmei/alive-progress",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/rsalmei/alive-progress"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic4.zhimg.com/80/v2-9fde8dbdaaca7120aa07d1deaa4c8483_720w.jpg",alt:"https://pic4.zhimg.com/80/v2-9fde8dbdaaca7120aa07d1deaa4c8483_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic2.zhimg.com/v2-ad7829884b8f61051be639d54dc00a01_b.jpg",alt:"https://pic2.zhimg.com/v2-ad7829884b8f61051be639d54dc00a01_b.jpg"}})]),t._v(" "),s("p",[s("strong",[t._v("六、可视化进度条")])]),t._v(" "),s("p",[t._v("用 PySimpleGUI 得到图形化进度条，我们可以加一行简单的代码，在命令行脚本中得到图形化进度条，也是使用pip进行下载")]),t._v(" "),s("p",[t._v("示例代码")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic3.zhimg.com/80/v2-c0fe7244d948af8ad052137da57e645a_720w.jpg",alt:"https://pic3.zhimg.com/80/v2-c0fe7244d948af8ad052137da57e645a_720w.jpg"}})]),t._v(" "),s("p",[t._v("展现形式")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://pic3.zhimg.com/v2-2ead8fba626f2d25a58ecd46953950b2_b.jpg",alt:"https://pic3.zhimg.com/v2-2ead8fba626f2d25a58ecd46953950b2_b.jpg"}})]),t._v(" "),s("h1",{attrs:{id:""}},[s("a",{staticClass:"header-anchor",attrs:{href:"#"}},[t._v("#")])])],1)}),[],!1,null,null,null);a.default=e.exports}}]);
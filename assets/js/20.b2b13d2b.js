(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{637:function(s,t,n){"use strict";n.r(t);var a=n(3),e=Object(a.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("Boxx",{attrs:{changeTime:"10000"}}),s._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"title"},[s._v("前言")]),n("p",[s._v("Transformer的numpy实现")])]),s._v(" "),n("p",[s._v("下面的代码自下而上的实现Transformer的相关模块功能。这份文档只实现了主要代码。由于时间关系，我无法实现所有函数。对于没有实现的函数，默认用全大写函数名指出，如SOFTMAX")]),s._v(" "),n("p",[s._v("由于时间限制，以下文档只是实现了Transformer前向传播的过程。")]),s._v(" "),n("h2",{attrs:{id:"输入层"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#输入层"}},[s._v("#")]),s._v(" 输入层")]),s._v(" "),n("p",[s._v("输入层包括Word Embedding和Positional Encoding。Word Embedding可以认为是预训练的词向量，Positional Encoding用于捕获词语的相对位置信息。")]),s._v(" "),n("p",[s._v("$\\begin{aligned} PE(pos, 2i) &= sin(pos / 10000^{\\frac{2i}{d}}) \\ PE(pos, 2i+1) &= cos(pos / 10000^{\\frac{2i}{d}}) \\end{aligned}$")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Word embedding matrix。通常从文件读入，这里随机初始化")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# word_embedding = np.arange(10)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# word_embedding.reshape(vocabulary_size, word_embedding_size)")]),s._v("\n\nmax_seq_len "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 假定的最大序列长度")]),s._v("\nposition_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Position Embedding的维度")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# position_encoding是一个类似于word embeding的二维矩阵")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 其中pos是序列中词语的位置，j是维度")]),s._v("\nposition_encoding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("pos "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("power"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("j "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" position_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" j "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n          "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" pos "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_seq_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Shape of position encoding: {}"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 每个position encoding的偶数列使用sin，奇数列使用cos处理")]),s._v("\nposition_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nposition_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cos"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 为了对文本长度对齐，加上Padding行")]),s._v("\npadding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nposition_encoding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("vstack"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("padding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Shape of position encoding after adding padding: {}"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("position_encoding")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sentence_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    给定一个batch的句子，输出这些句子的Position Embedding\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 模拟输入，batch_size=4")]),s._v("\n    sentence_lens "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Shape of input: {}"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("input_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 生成输入的位置索引，shape[batch_size, max_seq_len]")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 避开0的索引，不够长度的部分采用0填充")]),s._v("\n    pos_index "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_seq_len "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" sentence_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 利用pos_index在position_encoding中进行Lookup")]),s._v("\n    position_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LOOKUP"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pos_index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回维度[batch_size, max_seq_len, position_size]")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" position_embedding\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("word_embdding")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sentence_words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    给定一个batch句子，输出这些句子的Word Embedding\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将word转换为index，通常输入前就做完了")]),s._v("\n    word_index "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" WORD2INDEX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sentences_words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    word_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LOOKUP"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_embedding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回维度[batch_size, max_seq_len, word_embedding_size]")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" word_embedding\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br")])]),n("p",[s._v("输出")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("Shape of position encoding: (200, 512)\nShape of position encoding after adding padding: (201, 512)\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("p",[s._v("得到positional encoding和word embedding之后，将两部分拼接，得到输入向量")]),s._v(" "),n("h2",{attrs:{id:"层标准化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#层标准化"}},[s._v("#")]),s._v(" 层标准化")]),s._v(" "),n("p",[s._v("层标准化将数据标准化为均值为0，标准差为1.以下是实现代码")]),s._v(" "),n("p",[s._v("$BN(x_i)=\\alpha \\times \\frac{x_i - \\mu}{\\sqrt{\\delta^2 + \\epsilon}}+\\beta$")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("base_layer_norm")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    标准化张量x,假设x是三维张量，即\n    x.shape = (B, L, D)\n    通常第2维是我们要标准化的维度\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 求均值")]),s._v("\n    mean "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 求标准差")]),s._v("\n    std "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("std"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" std\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("layer_norm")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    引入可学习参数gamma、beta, epsilon用来防止发生数值计算错误\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 求均值")]),s._v("\n    mean "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("， keepdims"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 求标准差")]),s._v("\n    std "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("std"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" keepdims"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" gamma "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("std "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" epsilon"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" beta"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br")])]),n("h2",{attrs:{id:"缩放点积"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#缩放点积"}},[s._v("#")]),s._v(" 缩放点积")]),s._v(" "),n("p",[s._v("因为缩放点积(Scaled dot-product Attention)是Self-Attention的基础，因此这里先实现它。该模块输入是K,Q,V三个张量，输出Context上下文张量和Attention张量")]),s._v(" "),n("p",[s._v("$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("scaled_dot_product_attention")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    Args:\n        query: [batch_size, query_len, query_size]\n        key: [batch_size, key_len, key_size]\n        value: [batch_size, value_len, value_size]\n    """')]),s._v("\n    scale "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 缩放比例")]),s._v("\n    att "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("swapaxes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" scale\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 利用softmax将att转换为一个概率分布")]),s._v("\n    att "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SOFTMAX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("att"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 得到上下文张量")]),s._v("\n    context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("att"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" contenx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" att\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br")])]),n("h2",{attrs:{id:"multi-head-attention"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#multi-head-attention"}},[s._v("#")]),s._v(" Multi-head Attention")]),s._v(" "),n("p",[s._v("论文中使用了8个head，也就是把上述的K，Q，V三个张量按照维度分为8份，每份都经过仿射变换后送入到缩放点积中。")]),s._v(" "),n("p",[s._v("主要流程为：将K，Q，V进行仿射变换，得到对应的query，key和value；然后将它们根据head数目进行维度划分，送入到对应的缩放点积模块进行训练，得到Context张量和Attention张量；多个head的Context张量拼接后经过线性变换就得到了全局的Context张量；最后为了使模型能够更深，收敛更快，对输出加上了dropout，残差连接和层标准化。")]),s._v(" "),n("p",[s._v("下面是代码实现：")]),s._v(" "),n("p",[s._v("$MultiHead(Q,K,V)=Concat(head_1, head_2,\\cdots,head_h)W_c + b_c$")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("multihead_attention")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    Args:\n        query, key, value和缩放点积部分一致\n        num_heads: multi-head attention 个数\n        input_dim: 输入维度\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 恒等映射的残差，先保存下来")]),s._v("\n    residual "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" query\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 每个head分到的维度大小")]),s._v("\n    per_head "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" input_dim "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v(" num_heads\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 对query，key，value进行仿射运算")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# W_q,W_k,W_v是三个可学习二维矩阵，shape=[input_dim, (input_dim // num_heads)*num_heads]")]),s._v("\n    query"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_q"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_q\n    key "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_k\n    value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_v\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 根据每个head分到的维度对query，key，value重新切分")]),s._v("\n    qeury "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" per_head"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    key "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" per_head"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" per_head"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 对切分的query，key，value进行缩放点积")]),s._v("\n    context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" att "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scaled_dot_product_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将各个head的上下文向量拼接得到最终的context向量")]),s._v("\n    context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("batch_size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" per_head "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# context还需要经过一个线性变换,其中W_c是可学习二维矩阵，shape=[input_dim, input_dim]")]),s._v("\n    context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_c\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# dropout层")]),s._v("\n    context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" DROPOUT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出前进行残差连接和层标准化")]),s._v("\n    output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" layer_norm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("residual "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" att\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br")])]),n("h2",{attrs:{id:"mask"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#mask"}},[s._v("#")]),s._v(" Mask")]),s._v(" "),n("p",[s._v("Transformer中有Padding Mask和Sequence Mask。Padding Mask在计算Attention时用来消除某些位置的Attention值，使其在上下文张量中不起作用。Sequence Mask用于Decoder部分，主要是Mask掉当前输出词之后的序列，因为解码过程中是不知道后续词信息的。")]),s._v(" "),n("p",[s._v("为简单起见，上面的Attention都没有考虑Padding Mask。")]),s._v(" "),n("h2",{attrs:{id:"feed-forward层"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#feed-forward层"}},[s._v("#")]),s._v(" Feed Forward层")]),s._v(" "),n("p",[s._v("该全连接网络首先将输入x做了一次仿射变换，然后经过ReLU激活函数，再做一次仿射变化，得到最终的输出。")]),s._v(" "),n("p",[s._v("$FFN(x)=ReLU(xW_1+b_1)W_2 + b_2$")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("feed_forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 进行一次仿射变换，其中W_1和b_1分别为矩阵和偏置")]),s._v("\n    out "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_1\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 施加激活函数")]),s._v("\n    out "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ReLU"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 再进行仿射运算，其中W_2和b_2分别为矩阵和偏置")]),s._v("\n    out "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_2\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Dropout")]),s._v("\n    out "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" DROPOUT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加残差连接和层标准化")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" layer_norm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br")])]),n("h2",{attrs:{id:"encoder"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#encoder"}},[s._v("#")]),s._v(" Encoder")]),s._v(" "),n("p",[s._v("整个的Encoder有流程，每一层都是Multi-head Attention和Feed Forward模块组成。代码如下：")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("EncoderLayer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    Encoder部分一层的结构表示\n    每层中有Multi-head Attention和Feed Forward前向网络\n    """')]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        一些参数设置，如head大小，输入维度等\n        """')]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("encode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Multi-head Attention")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 先从inputs中获得对应的query，key，value")]),s._v("\n        query "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_QUERY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        key "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_KEY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_VALUE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" multihead_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Feed forward层")]),s._v("\n        output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" feed_forward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Encoder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    完整Encoder的表示\n    """')]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 定义Encoder所有的层")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("encoder_layers "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("layer1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" layer2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("layer6"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获得嵌入表示")]),s._v("\n        word_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_embedding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        position_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        final_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" position_embedding\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一层层进行编码")]),s._v("\n        final_attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" layer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("encoder_layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" layer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("encode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("final_embedding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            final_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# output只返回最后一层，attention全部返回")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br")])]),n("h2",{attrs:{id:"decoder"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#decoder"}},[s._v("#")]),s._v(" Decoder")]),s._v(" "),n("p",[s._v("Decoder的除了和Encoder一样，有Multi-head Attention和Feed Forward外，还有一层Masked Multi-head Attention在最下面。代码如下：")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DecoderLayer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    Decoder部分一层的结构表示\n    每层中有两个Multi-head Attention和一个Feed Forward前向网络模块\n    """')]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("decode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoder_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" decoder_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        与Encoder不同，Decoder不仅关注自己的输入，还要考虑Encoder的输出\n        """')]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 下层Multi-head Attention")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 先从decoder_inputs中获得对应的query，key，value")]),s._v("\n        query "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" decoder_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_QUERY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        key "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" decoder_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_KEY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" decoer_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_VALUE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" multihead_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 上层Multi-head Attention")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 再从encoder_outputs中获取key和value，decoder的output中获取query")]),s._v("\n        query "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_QUERY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        key "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" encoder_outputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_KEY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" encoder_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GET_VALUE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" multihead_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_heads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Feed forward层")]),s._v("\n        output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" feed_forward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attention2\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Decoder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    完整的Decoder表示\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 定义Dncoder所有的层")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decoder_layers "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("layer1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" layer2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("layer6"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoder_outputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获得嵌入表示")]),s._v("\n        word_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_embedding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        position_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" position_encoding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs_lens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        final_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_embedding "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" position_embedding\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Sequence Mask。解码过程中要做Sequence Mask")]),s._v("\n        seq_mask "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SEQUENCE_MASK"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一层层进行解码")]),s._v("\n        self_attentions "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        context_attentions "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" layer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decoder_layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context_attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" layer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("encoder_outputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" final_embedding"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            self_attentions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            context_attentions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# output只返回最后一层，attention全部返回")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self_attentions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context_attentions\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br")])]),n("h2",{attrs:{id:"transformer整体"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transformer整体"}},[s._v("#")]),s._v(" Transformer整体")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    Transformer整体代码\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        参数设置：参数主要有\n        Args:\n            src_vocab_size: 源语言词汇表大小\n            src_max_len: 源语言语句最大长度\n            tgt_vocab_size: 目标语言词汇表大小\n            tgt_max_len: 目标语言语句最大长度\n            num_layers=6: 默认Encoder和Decoder为6层\n            inputs_dim=512: 输入维度默认为512\n            num_heads=8: 默认Multi-head Attention个数为8\n            feed_forward_dim=2048：前馈网络维度\n            drop_out=0.2: Dropout概率\n        """')]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("encoder "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Encoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造编码器")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decoder "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Decoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造解码器")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" src_seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" src_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tgt_seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tgt_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n        编解码一个batch的过程\n        Args:\n            src_seq: 源语言序列\n            src_len: 源语言序列长度\n            tgt_seq: 目标语言序列\n            tgt_len: 目标语言序列长度\n        """')]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编码过程")]),s._v("\n        output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoder_attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("encoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("forward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("src_seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" src_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 解码过程")]),s._v("\n        output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context_attention "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("forward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tgt_seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tgt_len"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 最终要输出概率，所以最终结果还要经过线性层和softmax层")]),s._v("\n        output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" W_T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_T "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 其中，W_T和b_T是线性层的二维矩阵和偏置")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出概率")]),s._v("\n        output "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SOFTMAX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoder_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self_attention"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context_attention\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br")])])],1)}),[],!1,null,null,null);t.default=e.exports}}]);
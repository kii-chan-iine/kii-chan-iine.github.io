<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>小样本-Few-short Learning | KII IINE</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="manifest" href="/manifest.json">
    <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2c2c2c">
    <meta name="description" content="明早一起去看海 望向未来">
    <meta name="theme-color" content="#22979b">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#22979b">
    <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <meta name="google-site-verification" content="XCppppl60fPQTlwxDodwZIhMarkybEgwVpcEz85KTuQ">
    
    <link rel="preload" href="/assets/css/0.styles.c67cb200.css" as="style"><link rel="preload" href="/assets/js/app.dcf74483.js" as="script"><link rel="preload" href="/assets/js/3.a67abeb3.js" as="script"><link rel="preload" href="/assets/js/1.c373aa88.js" as="script"><link rel="preload" href="/assets/js/25.02d45b74.js" as="script"><link rel="preload" href="/assets/js/11.747f0d2b.js" as="script"><link rel="prefetch" href="/assets/js/10.0c65cdf0.js"><link rel="prefetch" href="/assets/js/12.b6c3bfcf.js"><link rel="prefetch" href="/assets/js/13.7d5668c8.js"><link rel="prefetch" href="/assets/js/14.dbeeea81.js"><link rel="prefetch" href="/assets/js/15.bba7d888.js"><link rel="prefetch" href="/assets/js/16.c1002d1a.js"><link rel="prefetch" href="/assets/js/17.8931228a.js"><link rel="prefetch" href="/assets/js/18.18dcf903.js"><link rel="prefetch" href="/assets/js/19.9bf7007f.js"><link rel="prefetch" href="/assets/js/20.7d9d5139.js"><link rel="prefetch" href="/assets/js/21.e2cfc140.js"><link rel="prefetch" href="/assets/js/22.825b0326.js"><link rel="prefetch" href="/assets/js/23.374f1eeb.js"><link rel="prefetch" href="/assets/js/24.b3fd754c.js"><link rel="prefetch" href="/assets/js/26.ef7c9433.js"><link rel="prefetch" href="/assets/js/27.aaad4a00.js"><link rel="prefetch" href="/assets/js/28.cf714528.js"><link rel="prefetch" href="/assets/js/29.685a6df7.js"><link rel="prefetch" href="/assets/js/30.dcc42b3e.js"><link rel="prefetch" href="/assets/js/31.18ceb4c4.js"><link rel="prefetch" href="/assets/js/32.071e66ac.js"><link rel="prefetch" href="/assets/js/33.6c0e304d.js"><link rel="prefetch" href="/assets/js/34.056913ea.js"><link rel="prefetch" href="/assets/js/35.24e976e5.js"><link rel="prefetch" href="/assets/js/36.91e6f93b.js"><link rel="prefetch" href="/assets/js/37.3a1d11e0.js"><link rel="prefetch" href="/assets/js/38.ef3a36fd.js"><link rel="prefetch" href="/assets/js/39.985d7a9e.js"><link rel="prefetch" href="/assets/js/4.09dda623.js"><link rel="prefetch" href="/assets/js/40.85ece0cf.js"><link rel="prefetch" href="/assets/js/41.ef116594.js"><link rel="prefetch" href="/assets/js/42.f03f2a48.js"><link rel="prefetch" href="/assets/js/43.a411e1d0.js"><link rel="prefetch" href="/assets/js/44.af5e3c15.js"><link rel="prefetch" href="/assets/js/45.7a2237a3.js"><link rel="prefetch" href="/assets/js/46.ecfc8246.js"><link rel="prefetch" href="/assets/js/5.9efeece9.js"><link rel="prefetch" href="/assets/js/6.45c24d02.js"><link rel="prefetch" href="/assets/js/7.3391c463.js"><link rel="prefetch" href="/assets/js/8.1d292254.js"><link rel="prefetch" href="/assets/js/9.49750083.js">
    <link rel="stylesheet" href="/assets/css/0.styles.c67cb200.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>KII IINE</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>明早一起去看海 望向未来</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>KII IINE</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2022
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/favicon.ico" alt="KII IINE" class="logo"> <span class="site-name">KII IINE</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CV/" class="nav-link"><i class="undefined"></i>
  CV
</a></li><li class="dropdown-item"><!----> <a href="/categories/深度学习/" class="nav-link"><i class="undefined"></i>
  深度学习
</a></li><li class="dropdown-item"><!----> <a href="/categories/闲言碎语/" class="nav-link"><i class="undefined"></i>
  闲言碎语
</a></li><li class="dropdown-item"><!----> <a href="/categories/Exp/" class="nav-link"><i class="undefined"></i>
  Exp
</a></li><li class="dropdown-item"><!----> <a href="/categories/Hadoop/" class="nav-link"><i class="undefined"></i>
  Hadoop
</a></li><li class="dropdown-item"><!----> <a href="/categories/funny/" class="nav-link"><i class="undefined"></i>
  funny
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/thinks/" class="nav-link"><i class="undefined"></i>
  thinks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Music/" class="nav-link"><i class="undefined"></i>
  Music
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/project/" class="nav-link"><i class="iconfont icon-project"></i>
  Project
</a></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kii-chan-iine/kii-chan-iine.github.io/tree/develop" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="mailto:kaichen1993@hotmail.com" class="nav-link external"><i class="iconfont icon-Gmail"></i>
  Mail
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/avatar.jpeg" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    KII IINE
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>29</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>12</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CV/" class="nav-link"><i class="undefined"></i>
  CV
</a></li><li class="dropdown-item"><!----> <a href="/categories/深度学习/" class="nav-link"><i class="undefined"></i>
  深度学习
</a></li><li class="dropdown-item"><!----> <a href="/categories/闲言碎语/" class="nav-link"><i class="undefined"></i>
  闲言碎语
</a></li><li class="dropdown-item"><!----> <a href="/categories/Exp/" class="nav-link"><i class="undefined"></i>
  Exp
</a></li><li class="dropdown-item"><!----> <a href="/categories/Hadoop/" class="nav-link"><i class="undefined"></i>
  Hadoop
</a></li><li class="dropdown-item"><!----> <a href="/categories/funny/" class="nav-link"><i class="undefined"></i>
  funny
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/thinks/" class="nav-link"><i class="undefined"></i>
  thinks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Music/" class="nav-link"><i class="undefined"></i>
  Music
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/project/" class="nav-link"><i class="iconfont icon-project"></i>
  Project
</a></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kii-chan-iine/kii-chan-iine.github.io/tree/develop" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="mailto:kaichen1993@hotmail.com" class="nav-link external"><i class="iconfont icon-Gmail"></i>
  Mail
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>小样本-Few-short Learning</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>KII IINE</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2022
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">小样本-Few-short Learning</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>kii</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>7/13/2021</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>deeplearn</span></i></div></div> <div class="theme-reco-content content__default"><div id="boxx" data-v-f4ca0dac><div data-v-f4ca0dac><p v-if="true" class="custom-block-title" data-v-f4ca0dac></p> <p v-if="true" data-v-f4ca0dac></p></div></div> <div class="custom-block tip"><p class="title">前言</p><p>整理了图像和NLP领域处理小样本的方法。</p></div> <h1 id="few-short-learning-小样本学习"><a href="#few-short-learning-小样本学习" class="header-anchor">#</a> Few-short Learning (小样本学习)</h1> <h2 id="总述"><a href="#总述" class="header-anchor">#</a> 总述</h2> <p>Few-short learning的目标不是让机器识别训练集中图片并且泛化到测试集,而是<font color="red">让机器自己学会学习</font>。</p> <p>在few-shot learning中有两个常用的术语：</p> <ul><li><p>k-way：the support set has k classes.</p></li> <li><p>n-shot：every class has n exampples.</p></li></ul> <h3 id="流程"><a href="#流程" class="header-anchor">#</a> 流程</h3> <ol><li>在一个很大的数据集上学习一个相似度函数。比如imagenet</li> <li>利用相似度进行预测。选择相似度高的作为预测结果。</li></ol> <h3 id="几个数据集"><a href="#几个数据集" class="header-anchor">#</a> 几个数据集</h3> <p>omniglot</p> <p>Mini-Imagenet</p> <h2 id="预训练模型"><a href="#预训练模型" class="header-anchor">#</a> <font color="orange">预训练模型</font></h2> <p>预训练（通用领域），然后(特定领域)Finetune：获得一定量的标注数据，然后基于一个基础网络进行微调。（这里有很多训练的trick，包括如何设置固定层和学习率等），如图3。这个方法可以相对较快，依赖数据量也不必太多，效果还行。</p> <h3 id="余弦相似度"><a href="#余弦相似度" class="header-anchor">#</a> 余弦相似度</h3> <p>**余弦相似度Cosine Similarity，**假设有两个单位向量，它们的夹角记为 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> ，此时余弦相似度为： <img src="https://www.zhihu.com/equation?tex=cos+%5Ctheta+%3D+x%5ET+w" alt="[公式]"> ，由此可以看出其实就是x在w方向上的投影长度，因此它的取值范围就是 <img src="https://www.zhihu.com/equation?tex=%5B-1%2C+1%5D" alt="[公式]"> 。</p> <img src="https://pic2.zhimg.com/80/v2-8ff7c2824659e0e3d04fc09f45432fd1_720w.jpg" alt="img" style="zoom:33%;"> <p>那么如果两个向量不是单位向量，此时就需要对其进行归一化。此时计算余弦相似度的公式为：</p> <p><img src="https://www.zhihu.com/equation?tex=cos+%5Ctheta+%3D+%5Cfrac%7Bx%5ETw%7D%7B+%5Cparallel+x+%5Cparallel+_2+%2B+%5Cparallel+w+%5Cparallel+_2+%7D" alt="[公式]"></p> <h3 id="softmax"><a href="#softmax" class="header-anchor">#</a> Softmax</h3> <h3 id="few-shot-prediction-using-pretrain-cnn"><a href="#few-shot-prediction-using-pretrain-cnn" class="header-anchor">#</a> <strong>Few-shot Prediction using pretrain CNN</strong></h3> <p><img src="https://pic2.zhimg.com/80/v2-22028b8acc7be9c1bb8b6e3713d0218d_720w.jpg" alt="img"></p> <p>通过神经网络输出的特征向量进行求平均和归一化得到三个类别的表征 <img src="https://www.zhihu.com/equation?tex=%5Cmu_1%2C+%5Cmu_2%2C+%5Cmu_3" alt="[公式]"> ,且他们三个的2范围都为单位向量。做分类的时候，使用query的特征向量 <img src="https://www.zhihu.com/equation?tex=q" alt="[公式]"> 和三个表征进行计算余弦相似度。</p> <p>令 <img src="https://www.zhihu.com/equation?tex=M+%3D+%5Cbegin+%7Bbmatrix%7D++%5Cmu_1+%5C%5C+%5Cmu_2+%5C%5C+%5Cmu_3+%5Cend+%7Bbmatrix%7D" alt="[公式]"> ，则有 <img src="https://www.zhihu.com/equation?tex=p+%3D+softmax%28Mq%29+%3D+%5Cbegin+%7Bbmatrix%7D+%5Cmu_1%5ETq+%5C%5C+%5Cmu_2%5ETq+%5C%5C+%5Cmu_3%5ETq+%5C%5C+%5Cend+%7Bbmatrix%7D" alt="[公式]"></p> <p><strong>Fine-Tuning流程：</strong></p> <ul><li>将support set中每个样本记做 <img src="https://www.zhihu.com/equation?tex=%28x_j%2C+y_j%29" alt="[公式]"> 其中 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 表示图片， <img src="https://www.zhihu.com/equation?tex=y_j" alt="[公式]"> 表示标签。</li> <li>预训练的神经网络<img src="https://www.zhihu.com/equation?tex=f%28x_j%29+" alt="[公式]"> 对support set中的样本进行特征提取，得到对应的特征向量</li> <li><img src="https://www.zhihu.com/equation?tex=p_j+%3D+softmax%28w+%5Ccdot+f%28x_j%29+%2B+b" alt="[公式]"> 就是预测结果。通常会在support set上对w和b进行fine tuning，这样能大幅度提升准确率。</li> <li><img src="https://www.zhihu.com/equation?tex=%5Cmin+%5Csum_j+CrossEntropy%28y_j%2C+p_j%29+%2B+Regularization" alt="[公式]"></li></ul> <h2 id="基于metric-大概是与样本之间的距离有关"><a href="#基于metric-大概是与样本之间的距离有关" class="header-anchor">#</a> 基于metric：（大概是与样本之间的距离有关）</h2> <p>该方法是对<font color="red">样本间距离分布</font>进行建模，使得属于同类样本靠近，异类样本远离。简单地，我们可以采用无参估计的方法，如<strong>KNN</strong>。KNN虽然不需要训练，但效果依赖距离度量的选取, 一般采用的是一个比较随意的距离计算（L2）。另一种，也是目前比较好的方法，即通过学习<strong>一个端到端的最近邻分类器</strong>，它同时受益于带参数和无参数的优点，使得不但能快速的学习到新的样本，而且能对已知样本有很好的泛化性。下面介绍3个相关的方法。</p> <h3 id="孪生网络-siamese-neural-networks-1"><a href="#孪生网络-siamese-neural-networks-1" class="header-anchor">#</a> <font color="orange"><strong>孪生网络 （Siamese Neural Networks）</strong> <a href="#refer-anchor-1"><sup>1</sup></a></font></h3> <h4 id="learning-pari-wise-similarity-score"><a href="#learning-pari-wise-similarity-score" class="header-anchor">#</a> learning pari-wise Similarity score</h4> <ul><li><strong>构建数据集</strong></li></ul> <p>每次取两个样本取比较他们的相似度。数据集要求比较大，利用数据集带标签，利用<strong>训练集</strong>构建正负样本。正样本可以使得神经网络什么东西是同一类，负样本可以使神经网络了解事物的区别。</p> <ul><li><strong>构建CNN for Feature Extraction</strong></li></ul> <p>输入一张图片x，通过CNN提取特征输出一个特征向量f(x)--flatten之后的结果。</p> <ul><li><strong>训练Siamese network</strong></li></ul> <p>通过对两张图片的特征提取得到两个特征向量，然后使用全连接层对特征向量进行处理得到一个标量，使用非线性激活函数对标量进行激活，得到的输出在0-1之间，作为两张图片的相似度度量。</p> <p><img src="https://pic1.zhimg.com/80/v2-d92fd4c422119e8dbde6a0029d63c5d8_720w.jpg" alt="img"></p> <p>模型训练完成之后，进行one-shot prediction（当然也可使是n-shot这里只是举例）6-way 1-shot prediction，训练siamese network的训练数据集中并不包括这6个类别，这就是few shot learning的难点所在。</p> <p><img src="https://pic3.zhimg.com/80/v2-6f8fc94ff2b6342ef54f2dd3b7bd2cbe_720w.jpg" alt="img"></p> <h4 id="triplet-loss-学习到的是一个好的embedding"><a href="#triplet-loss-学习到的是一个好的embedding" class="header-anchor">#</a> Triplet Loss--学习到的是一个好的embedding</h4> <p>第二种训练siamese network的方法。首先在训练样本集中随机选取一张图片作为anchor，然后从选中样本的类别中再选一张图片作为正样本（positive sample），然后在除此类别之外的类别中选取张图片作为负样本（negtive sample）。</p> <p>由此得到三张图片，分别给入神经网络进行特征提取，由此进行计算损失时， <img src="https://www.zhihu.com/equation?tex=d%5E%7B%2B%7D" alt="[公式]"> 应该比较小，而 <img src="https://www.zhihu.com/equation?tex=d%5E%7B-%7D" alt="[公式]"> 应该很大。</p> <p><img src="https://pic3.zhimg.com/80/v2-471ba5e8ffdc4bef4ce526b6cd24f5ce_720w.jpg" alt="img"></p> <p>由此也可以理解为<strong>经过神经网络进行特征映射</strong>，最终映射到同一特征空间中，进行举例度量：</p> <img src="https://pic2.zhimg.com/80/v2-5ce2cdc5eefaf6abedae07f4984b1f11_720w.jpg" alt="img" style="zoom:67%;"> <p>也即是模型鼓励损失函数中<img src="https://www.zhihu.com/equation?tex=d%5E%7B%2B%7D" alt="[公式]">尽可能地小，<img src="https://www.zhihu.com/equation?tex=d%5E%7B-%7D" alt="[公式]">尽可能地大，这样才能在特征空间中将其分开。在这个过程中定义一个阈值 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> ，如果 <img src="https://www.zhihu.com/equation?tex=d%5E%7B-%7D+%5Cge+d%5E%7B%2B%7D+%2B+%5Calpha" alt="[公式]"> 此时就没有损失，否则损失就为 <img src="https://www.zhihu.com/equation?tex=d%5E%7B%2B%7D+%2B+%5Calpha+-+d%5E%7B-%7D" alt="[公式]"> ，即是： <img src="https://www.zhihu.com/equation?tex=Loss%28x%5Ea%2C+x%5E%2B%2C+x%5E%7B-%7D%29+%3D+%5Cmax%5C%7B+0%2C++d%5E%7B%2B%7D+%2B+%5Calpha+-+d%5E%7B-%7D%5C%7D" alt="[公式]"> 。</p> <hr> <p>对输入的结构进行限制，自动发现新样本上的泛化特征。</p> <p>通过一个有监督的基于孪生网络的度量学习来训练，然后重用那个网络所提取的特征进行one/few-shot学习。它是一个双路的神经网络，训练时，通过组合不同类的样本成对，同时输入网络进行训练，在最上层通过一个距离的交叉熵进行loss的计算。在预测的时候，以5way-5shot为例，从5个类中随机抽取5个样本，把这个mini-batch=25的数据输入网络，最后获得25个值，取分数最高对应的类别作为预测结果。</p> <h4 id="小结"><a href="#小结" class="header-anchor">#</a> 小结</h4> <p>总结一下训练siamese network的思路：</p> <ul><li>首先使用一个比较大的数据集训练siamese network。</li> <li>然后给定一个k-way n-shot的support set，其特点在于训练集中并不包含support set中的k个类别。</li> <li>给定一个query，去预测其类别。使用Siamese network进行计算相似度或距离。</li></ul> <h3 id="匹配网络-matching-networks-2"><a href="#匹配网络-matching-networks-2" class="header-anchor">#</a> 匹配网络（matching networks） <a href="#refer-anchor-2"><sup>2</sup></a></h3> <p>不改变网络模型的前提下能对未知类别生成标签，其主要创新体现在建模过程和训练过程上。</p> <p>对于建模过程的创新，文章提出了基于memory和attantion的matching nets，使得可以快速学习。</p> <p>对于训练过程的创新，文章基于传统机器学习的一个原则，即训练和测试是要在同样条件下进行的，提出在训练的时候不断地让网络只看每一类的少量样本，这将和测试的过程是一致的。</p> <h3 id="原型网络-prototypical-networks-3"><a href="#原型网络-prototypical-networks-3" class="header-anchor">#</a> 原型网络 （Prototypical Networks） <a href="#refer-anchor-3"><sup>3</sup></a></h3> <p>该方法思想十分简单高效，效果也非常好。它学习一个度量空间， 通过计算和每个类别的原型表达的距离来进行分类。文章基于这样的想法：每个类别都存在一个聚在某单个原型表达周围的embedding，该类的原型是support set在embedding空间中的均值。然后，分类问题变成在<font color="red">embedding空间中的最近邻</font>。</p> <h2 id="基于graph-neural-network-4"><a href="#基于graph-neural-network-4" class="header-anchor">#</a> 基于graph neural network <a href="#refer-anchor-4"><sup>4</sup></a></h2> <p>这是一篇比较新的文章，提交到ICLR 2018[4]。他定义了一个图神经网络框架，端到端地学习消息传递的“关系”型任务。在这里，每个样本看成图的节点，该方法不仅学习节点的embedding，也学习边的embedding。如图9，在网络第一层5个样本通过边模型A～构建了图，接着通过图卷积（graph conv）获得了节点的embedding，然后在后面的几层继续用A～更新图、用graph conv更新节点embedding, 这样便构成了一个深度GNN，最后输出样本的预测标签。</p> <h2 id="基于元学习meta-learning-learn-to-learn"><a href="#基于元学习meta-learning-learn-to-learn" class="header-anchor">#</a> 基于<font color="red">元学习</font>meta learning--&gt;learn to learn</h2> <p>就是避免从0开始学习的方法。<strong>依靠少量的样本完成推理</strong>。</p> <p>我们希望它能够从之前的经验快速地学习新的技能，而不是把新的任务孤立地考虑。这个方法，我们称为元学习（learning to learn,或meta learning）, 使得我们的系统在它的整个生命周期中可以持续地学习各种各样的任务。</p> <p>meta learning是机器学习的一个子领域，它自动学习一些应用于机器学习实验的元数据，主要目的是使用这些元数据来自动学习如何在解决不同类型的学习问题时变得灵活，从而提高现有的学习算法。灵活性是非常重要的，因为<strong>每个学习算法都是基于一组有关数据的假设，即它是归纳偏(bias)的。<strong>这意味着如果bias与学习问题中的数据相匹配，那么学习就会很好。学习算法在一个学习问题上表现得非常好，但在下一个学习问题上表现得非常糟糕。这对机器学习或数据挖掘技术的使用造成了很大的限制，因为学习问题与不同学习算法的有效性之间的关系尚不清楚。
通过使用不同类型的元数据，如学习问题的属性，算法属性（如性能测量）或从之前数据推导出的模式，可以选择、更改或组合不同的学习算法，以有效地解决给定的学习问题。
元学习一般有两级，第一级是</strong>快速地获得每个任务中的知识</strong>，第二级是较慢地<strong>提取所有任务中学到的信息</strong>。下面从不同角度解释了元学习的方法</p> <ul><li>通过知识诱导来表达每种学习方法如何在不同的学习问题上执行，从而发现元知识。元数据是由学习问题中的数据特征（一般的，统计的，信息论的......）以及学习算法的特征（类型，参数设置，性能测量...）形成的。然后，另一个学习算法学习数据特征如何与算法特征相关。给定一个新的学习问题，测量数据特征，并且可以预测不同学习算法的性能。因此，至少在诱导关系成立的情况下，可以选择最适合新问题的算法。</li> <li>stacking. 通过组合一些（不同的）学习算法，即堆叠泛化。元数据是由这些不同算法的预测而形成的。然后，另一个学习算法从这个元数据中学习，以预测哪些算法的组合会给出好的结果。在给定新的学习问题的情况下，所选择的一组算法的预测被组合（例如通过加权投票）以提供最终的预测。由于每种算法都被认为是在一个问题子集上工作，所以希望这种组合能够更加灵活，并且能够做出好的预测。</li> <li>boosting. 多次使用相同的算法，训练数据中的示例在每次运行中获得不同的权重。这产生了不同的预测，每个预测都集中于正确预测数据的一个子集，并且结合这些预测导致更好（但更昂贵）的结果。</li> <li>动态偏选择(Dynamic bias selection)通过改变学习算法的感应偏来匹配给定的问题。这通过改变学习算法的关键方面来完成，例如假设表示，启发式公式或参数。</li> <li>learning to learn，研究如何随着时间的推移改进学习过程。元数据由关于以前的学习事件的知识组成，并被用于高效地开发新任务的有效假设。<strong>其目标是使用从一个领域获得的知识来帮助其他领域的学习</strong>。</li></ul> <p>在meta learning中，我们在训练集上训练一个训练过程(meta learner)来生产生一个分类器（learner）使得learner在测试集上获得高的精度。如下图</p> <h3 id="递归记忆模型-memory-augmented-neural-networks-5"><a href="#递归记忆模型-memory-augmented-neural-networks-5" class="header-anchor">#</a> 递归记忆模型 （Memory-Augmented Neural Networks） <a href="#refer-anchor-5"><sup>5</sup></a></h3> <p>文章基于神经网络图灵机（NTMs）的思想，因为NTMs能通过外部存储（external memory）进行短时记忆，并能通过缓慢权值更新来进行长时记忆，NTMs可以学习将表达存入记忆的策略，并如何用这些表达来进行预测。由此，文章方法可以快速准确地预测那些只出现过一次的数据。文章基于LSTM等RNN的模型，将数据看成序列来训练，在测试时输入新的类的样本进行分类。具体地，网络的输入把上一次的y (label)也作为输入，并且添加了external memory存储上一次的x输入，这使得下一次输入后进行反向传播时，可以让y (label)和x建立联系，使得之后的x能够通过外部记忆获取相关图像进行比对来实现更好的预测。这里的RNN就是meta-learner。</p> <h3 id="优化器学习-meta-learning-lstm-6"><a href="#优化器学习-meta-learning-lstm-6" class="header-anchor">#</a> 优化器学习  （meta-learning LSTM） <a href="#refer-anchor-6"><sup>6</sup></a></h3> <p>这些梯度优化算法包括momentum, adagrad, adadelta, ADAM等，无法在几步内完成优化，特别是在非凸的问题上，多种超参的选取无法保证收敛的速度。其次，不同任务分别随机初始化会影响任务收敛到好的解上。虽然finetune这种迁移学习能缓解这个问题，但**当新数据相对原始数据偏差比较大时，迁移学习的性能会大大下降。**我们需要一个系统的学习通用初始化，使得训练从一个好的点开始，它和迁移学习不同的是，它能保证该初始化能让finetune从一个好的点开始。</p> <p>**文章学习的是一个模新参数的更新函数或更新规则。**它不是在多轮的episodes学习一个单模型，而是在每个episode学习特定的模型。具体地，学习基于梯度下降的参数更新算法，采用LSTM表达meta learner，用其状态表达目标分类器的参数的更新，最终学会如何在新的分类任务上，对分类器网络(learner)进行初始化和参数更新。这个优化算法同时考虑一个任务的短时知识和跨多个任务的长时知识。文章设定目标为通过少量的迭代步骤捕获优化算法的泛化能力，由此meta learner可以训练让learner在每个任务上收敛到一个好的解。另外，通过捕获所有任务之前共享的基础知识，进而更好地初始化learner。</p> <h3 id="模型无关自适应-model-agnostic-7"><a href="#模型无关自适应-model-agnostic-7" class="header-anchor">#</a> 模型无关自适应（Model-Agnostic） <a href="#refer-anchor-7"><sup>7</sup></a></h3> <p>meta learning 的目标是在各种不同的学习任务上学出一个模型，使得可以仅用少量的样本就能解决一些新的学习任务。这种任务的挑战是模型需要结合之前的经验和当前新任务的少量样本信息，并避免在新数据上过拟合。</p> <p><strong>这个方法无需关心模型的形式</strong>，也不需要为meta learning增加新的参数，<strong>直接用梯度下降来训练learner</strong>。</p> <p>文章的核心思想是<font color="green"><strong>学习模型的初始化参数使得在一步或几步迭代后在新任务上的精度最大化</strong></font>。它学的不是模型参数的更新函数或是规则，它不局限于参数的规模和模型架构（比如用RNN或siamese）。<strong>它本质上也是学习一个好的特征</strong>使得可以适合很多任务（包括分类、回归、增强学习），并通过fine-tune来获得好的效果。</p> <p>文章提出的方法，可以学习任意标准模型的参数，并让该模型能快速适配。方法认为，一些中间表达更加适合迁移，比如神经网络的内部特征。因此面向泛化性的表达是有益的。</p> <p>是要找到一些对任务变化敏感的参数，使得当改变梯度方向，小的参数改动也会产生较大的loss.</p> <h1 id="长尾分布问题"><a href="#长尾分布问题" class="header-anchor">#</a> 长尾分布问题</h1> <p>https://zhuanlan.zhihu.com/p/158638078</p> <p>1）重采样（re-sampling）相关</p> <p>2）重加权（re-weighting）相关</p> <p>3）迁移学习（transfer learning）相关</p> <h1 id="nlp领域-文本增强"><a href="#nlp领域-文本增强" class="header-anchor">#</a> NLP领域-文本增强</h1> <h2 id="back-translation"><a href="#back-translation" class="header-anchor">#</a> back-translation</h2> <p>标注文本-&gt;翻译-&gt;在翻译回来。</p> <h2 id="eda-easy-data-augmentation"><a href="#eda-easy-data-augmentation" class="header-anchor">#</a> EDA-easy data augmentation</h2> <p>四种操作：</p> <ol><li>同义词替换：随机选n个同义词替换，(非停用词)</li> <li>随机插入：插入文本中某个非停用词的同义词</li> <li>随机交换：</li> <li>随机删除：按概率p随机删除</li></ol> <p>增强值$\alpha$</p> <p>没论证是否能够保证标签不变。只是通过一个图显示影响不大</p> <p>t-SNE 降维度</p> <p>数据量大，提升效果不好。预训练复杂模型效果可能不行。</p> <p>数据量少的时候，可能有几个点的提升</p> <h2 id="contextual-augmentation"><a href="#contextual-augmentation" class="header-anchor">#</a> Contextual Augmentation</h2> <ol><li><p>使用语言模型进行文本的替换</p> <ol><li>语言模型：用语言模型评价一句话是否合理或是人话</li> <li>数学上讲：P（合理句子）&gt;P（不合理句子）</li> <li>用文本中前n个字预测下一个字</li></ol></li> <li><p>语言模型结构：双向LSTM</p></li> <li><p>修改训练目标融入标签信息</p></li> <li><p>利用了语境信息</p></li></ol> <p>现有的方法：基于word-Net库，不好</p> <p>把标签也序列化，融入到训练过程中，从而保证替换后不会对原有的标签有损伤。</p> <h2 id="conditional-bert"><a href="#conditional-bert" class="header-anchor">#</a> Conditional Bert</h2> <ol><li>使用Bert模型结构</li></ol> <h2 id="lambada"><a href="#lambada" class="header-anchor">#</a> LAMBADA</h2> <p>Do Not Have Enough Data? Deep Learning to the Rescue!</p> <p>基于generative pre-training 2（GPT2）</p> <p>GPT也是深层的transformer模型，更复杂，深度更深</p> <img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20210712173432884.png" alt="image-20210712173432884" style="zoom:50%;"> <h2 id="uda-半监督学习"><a href="#uda-半监督学习" class="header-anchor">#</a> UDA-半监督学习</h2> <p>半监督学习：如何结合有标注数据，直接利用无标签数据</p> <p>数据增强是：如花使用有标注数据，构造更多有标签数据</p> <h3 id="平滑假设"><a href="#平滑假设" class="header-anchor">#</a> 平滑假设</h3> <ol><li><p>如果两个输入样本相似，那么模型输出结果也应当相似</p></li> <li><p>对样本做某种很小的扰动，得到x2</p></li> <li><p>训练目标：<strong>调整模型w，使得w1、w2接近</strong></p></li> <li><p>在这个过程中，y1和y2的实际值并不重要</p></li></ol> <h1 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h1> <div id="refer-anchor-1"></div> <ul><li>[1] G Koch, R Zemel, and R Salakhutdinov. Siamese neural networks for one-shot image recognition. In ICML Deep Learning workshop, 2015.</li></ul> <div id="refer-anchor-2"></div> <ul><li>[2] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. In Advances in Neural Information Processing Systems, pages 3630–3638, 2016.</li></ul> <div id="refer-anchor-3"></div> <ul><li>[3] Jake Snell, Kevin Swersky, and Richard S Zemel. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.</li></ul> <div id="refer-anchor-4"></div> <ul><li>[4] Victor Garcia, Joan Bruna. Few-shot learning with graph neural networs. Under review as a conference paper at ICLR 2018.</li></ul> <div id="refer-anchor-5"></div> <ul><li>[5] Santoro, Adam, Bartunov, Sergey, Botvinick, Matthew, Wierstra, Daan, and Lillicrap, Timothy. Meta-learning with memory-augmented neural networks. In International Conference on Machine Learning (ICML), 2016.</li></ul> <div id="refer-anchor-6"></div> <ul><li>[6] Ravi, Sachin and Larochelle, Hugo. Optimization as a model for few-shot learning. In International Conference on Learning Representations (ICLR), 2017.</li></ul></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">a year ago</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#总述" class="sidebar-link reco-side-总述" data-v-70334359>总述</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#流程" class="sidebar-link reco-side-流程" data-v-70334359>流程</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#几个数据集" class="sidebar-link reco-side-几个数据集" data-v-70334359>几个数据集</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#预训练模型" class="sidebar-link reco-side-预训练模型" data-v-70334359></a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#余弦相似度" class="sidebar-link reco-side-余弦相似度" data-v-70334359>余弦相似度</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#softmax" class="sidebar-link reco-side-softmax" data-v-70334359>Softmax</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#few-shot-prediction-using-pretrain-cnn" class="sidebar-link reco-side-few-shot-prediction-using-pretrain-cnn" data-v-70334359>Few-shot Prediction using pretrain CNN</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#基于metric-大概是与样本之间的距离有关" class="sidebar-link reco-side-基于metric-大概是与样本之间的距离有关" data-v-70334359>基于metric：（大概是与样本之间的距离有关）</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#孪生网络-siamese-neural-networks-1" class="sidebar-link reco-side-孪生网络-siamese-neural-networks-1" data-v-70334359></a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#匹配网络-matching-networks-2" class="sidebar-link reco-side-匹配网络-matching-networks-2" data-v-70334359>匹配网络（matching networks） [](#refer-anchor-2)</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#原型网络-prototypical-networks-3" class="sidebar-link reco-side-原型网络-prototypical-networks-3" data-v-70334359>原型网络 （Prototypical Networks） [](#refer-anchor-3)</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#基于graph-neural-network-4" class="sidebar-link reco-side-基于graph-neural-network-4" data-v-70334359>基于graph neural network [](#refer-anchor-4)</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#基于元学习meta-learning-learn-to-learn" class="sidebar-link reco-side-基于元学习meta-learning-learn-to-learn" data-v-70334359>基于learn to learn</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#递归记忆模型-memory-augmented-neural-networks-5" class="sidebar-link reco-side-递归记忆模型-memory-augmented-neural-networks-5" data-v-70334359>递归记忆模型 （Memory-Augmented Neural Networks） [](#refer-anchor-5)</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#优化器学习-meta-learning-lstm-6" class="sidebar-link reco-side-优化器学习-meta-learning-lstm-6" data-v-70334359>优化器学习  （meta-learning LSTM） [](#refer-anchor-6)</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#模型无关自适应-model-agnostic-7" class="sidebar-link reco-side-模型无关自适应-model-agnostic-7" data-v-70334359>模型无关自适应（Model-Agnostic） [](#refer-anchor-7)</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#back-translation" class="sidebar-link reco-side-back-translation" data-v-70334359>back-translation</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#eda-easy-data-augmentation" class="sidebar-link reco-side-eda-easy-data-augmentation" data-v-70334359>EDA-easy data augmentation</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#contextual-augmentation" class="sidebar-link reco-side-contextual-augmentation" data-v-70334359>Contextual Augmentation</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#conditional-bert" class="sidebar-link reco-side-conditional-bert" data-v-70334359>Conditional Bert</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#lambada" class="sidebar-link reco-side-lambada" data-v-70334359>LAMBADA</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#uda-半监督学习" class="sidebar-link reco-side-uda-半监督学习" data-v-70334359>UDA-半监督学习</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/FewShortLearning.html#平滑假设" class="sidebar-link reco-side-平滑假设" data-v-70334359>平滑假设</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><canvas id="vuepress-canvas-cursor"></canvas><!----><div class="vuepress-canvas-nest-element"></div><div class="kanbanniang" data-v-27e9bfa4><div class="banniang-container" style="display:;" data-v-27e9bfa4><div class="messageBox" style="position:fixed;right:75px;bottom:235px;opacity:0.75;height:max-content;width:200px;fon-szie:16px;display:none;" data-v-27e9bfa4></div> <div class="operation" style="display:;" data-v-27e9bfa4><i data-v-27e9bfa4><svg t="1572660425629" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6044" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M577.5584 307.848533l-21.345067-18.699733c-0.062933-0.061867-0.186667-0.123733-0.280533-0.186667l-44.305067-38.689067-53.752533 47.5648L127.009067 587.424l0 177.1392 0 155.0048c0 45.886933 37.454933 83.0976 83.610667 83.0976l183.966933 0L394.586667 735.8688c0-27.512533 22.448-49.8336 50.162133-49.8336l133.7728 0c27.714133 0 50.178133 22.321067 50.178133 49.8336L628.699733 1002.666667l183.966933 0c46.170667 0 83.610667-37.211733 83.610667-83.0976L896.277333 763.9424 896.277333 586.7712 578.5216 308.688 577.5584 307.848533z" p-id="6045" data-v-27e9bfa4></path> <path d="M990.637867 418.164267l-94.360533-82.600533 0-181.290667c0-36.714667-29.952-66.482133-66.894933-66.482133-36.941867 0-66.893867 29.767467-66.893867 66.482133l0 64.197333L556.213333 37.911467c-25.291733-22.103467-63.165867-22.103467-88.4256 0L33.348267 418.164267c-27.730133 24.247467-30.402133 66.264533-5.9808 93.808 24.437333 27.544533 66.692267 30.219733 94.407467 5.938133L512 176.376533l390.2432 341.533867c12.7072 11.130667 28.4608 16.600533 44.181333 16.600533 18.549333 0 37.0048-7.617067 50.209067-22.538667C1021.054933 484.4128 1018.382933 442.4128 990.637867 418.164267z" p-id="6046" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660394444" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5299" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M0 202.7V631c0 83.3 68.3 150.7 152.6 150.7h228.9l8 190.3 224.9-190.3h257c84.3 0 152.6-67.4 152.6-150.7V202.7C1024 119.4 955.7 52 871.4 52H152.6C68.3 52 0 119.4 0 202.7z m658.6 237.9c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S771 512 730.9 512c-40.2 0-72.3-31.7-72.3-71.4z m-220.9 0c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S550.1 512 510 512c-40.2 0-72.3-31.7-72.3-71.4z m-216.8 0c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S333.3 512 293.1 512c-40.1 0-72.2-31.7-72.2-71.4z" p-id="5300" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660570409" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2153" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 393.846154c-86.646154 0-157.538462 70.892308-157.538462 157.538461s70.892308 157.538462 157.538462 157.538462 157.538462-70.892308 157.538462-157.538462-70.892308-157.538462-157.538462-157.538461z m393.846154-118.153846h-102.4c-27.569231 0-51.2-13.784615-66.953846-35.446154l-45.292308-68.923077C677.415385 137.846154 643.938462 118.153846 608.492308 118.153846h-192.984616c-35.446154 0-68.923077 19.692308-84.676923 53.169231l-45.292307 68.923077c-13.784615 21.661538-39.384615 35.446154-66.953847 35.446154H118.153846c-43.323077 0-78.769231 35.446154-78.769231 78.76923v472.615385c0 43.323077 35.446154 78.769231 78.769231 78.769231h787.692308c43.323077 0 78.769231-35.446154 78.769231-78.769231V354.461538c0-43.323077-35.446154-78.769231-78.769231-78.76923zM512 787.692308c-129.969231 0-236.307692-106.338462-236.307692-236.307693s106.338462-236.307692 236.307692-236.307692 236.307692 106.338462 236.307692 236.307692-106.338462 236.307692-236.307692 236.307693z" p-id="2154" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660469241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6553" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M706.544835 64.021106h-6.500041a159.889547 159.889547 0 0 0-83.558068 23.557532c-54.583153 33.422204-86.949304 40.439014-104.486726 40.439014-17.538445 0-49.903573-7.016811-104.494912-40.445154a159.88136 159.88136 0 0 0-83.550905-23.551392h-6.507204a127.823224 127.823224 0 0 0-97.182366 44.702108l-172.836417 201.635323c-19.522636 22.774703-20.600177 56.050574-2.609431 80.047104l95.995331 127.994116a63.99757 63.99757 0 0 0 83.198887 17.024745v328.558038c0 52.93256 43.060725 95.995331 95.995331 95.995331h415.98011c52.934606 0 95.995331-43.062771 95.995331-95.995331V535.424502a64.028269 64.028269 0 0 0 42.240033 7.749498 64.013943 64.013943 0 0 0 46.990221-34.528398l63.996546-127.856993c11.522428-23.027459 8.125051-50.721195-8.632611-70.278623L803.743574 108.74675c-24.335245-28.421306-59.770292-44.725644-97.198739-44.725644z" p-id="6554" data-v-27e9bfa4></path></svg></i>
      <a target="_blank" href="https://github.com/kii-chan-iine" data-v-27e9bfa4><i data-v-27e9bfa4><svg t="1572660325062" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3809" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 3.413333c280.849067 0 508.586667 199.273813 508.586667 444.94848 0 140.427947-74.519893 265.53344-190.65856 347.11552V1020.586667l-222.839467-135.168c-30.859947 5.147307-62.552747 8.021333-95.085227 8.021333-280.845653 0-508.586667-199.28064-508.586666-445.078187C3.413333 202.687147 231.150933 3.413333 512 3.413333z m-158.96576 603.921067h317.805227c17.578667 0 31.812267-14.2336 31.812266-31.819093a31.798613 31.798613 0 0 0-31.812266-31.80544h-317.805227c-17.578667 0-31.812267 14.2336-31.812267 31.80544 0.116053 17.585493 14.349653 31.819093 31.812267 31.819093z m-63.511893-190.665387h444.951893c17.578667 0 31.812267-14.2336 31.812267-31.812266a31.802027 31.802027 0 0 0-31.812267-31.81568H289.522347a31.802027 31.802027 0 0 0-31.81568 31.81568c0 17.578667 14.2336 31.812267 31.81568 31.812266z" p-id="3810" data-v-27e9bfa4></path></svg></i></a> <i data-v-27e9bfa4><svg t="1572660347392" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4543" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 34.133333a486.4 486.4 0 1 0 486.4 486.4A486.4 486.4 0 0 0 512 34.133333z m209.4848 632.8064l-55.6032 55.466667-151.517867-151.125333-151.517866 151.1168-55.6032-55.466667 151.517866-151.108267L307.242667 364.714667l55.6032-55.466667 151.517866 151.125333 151.517867-151.1168 55.6032 55.466667-151.517867 151.099733z m0 0" p-id="4544" data-v-27e9bfa4></path></svg></i></div> <canvas id="banniang" width="216" height="281.6" class="live2d" style="position:fixed;right:90px;bottom:-20px;opacity:1;" data-v-27e9bfa4></canvas></div> <div class="showBanNiang" style="display:none;" data-v-27e9bfa4>
    看板娘
  </div></div><!----><div></div></div></div>
    <script src="/assets/js/app.dcf74483.js" defer></script><script src="/assets/js/3.a67abeb3.js" defer></script><script src="/assets/js/1.c373aa88.js" defer></script><script src="/assets/js/25.02d45b74.js" defer></script><script src="/assets/js/11.747f0d2b.js" defer></script>
  </body>
</html>

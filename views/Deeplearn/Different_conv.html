<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Convolution | KII IINE</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="manifest" href="/manifest.json">
    <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2c2c2c">
    <meta name="description" content="明早一起去看海 望向未来">
    <meta name="theme-color" content="#22979b">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#22979b">
    <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <meta name="google-site-verification" content="XCppppl60fPQTlwxDodwZIhMarkybEgwVpcEz85KTuQ">
    
    <link rel="preload" href="/assets/css/0.styles.c67cb200.css" as="style"><link rel="preload" href="/assets/js/app.65da1296.js" as="script"><link rel="preload" href="/assets/js/3.a67abeb3.js" as="script"><link rel="preload" href="/assets/js/1.c373aa88.js" as="script"><link rel="preload" href="/assets/js/23.d272b7b0.js" as="script"><link rel="preload" href="/assets/js/11.747f0d2b.js" as="script"><link rel="prefetch" href="/assets/js/10.0c65cdf0.js"><link rel="prefetch" href="/assets/js/12.1393d74c.js"><link rel="prefetch" href="/assets/js/13.7d5668c8.js"><link rel="prefetch" href="/assets/js/14.dbeeea81.js"><link rel="prefetch" href="/assets/js/15.dc20acad.js"><link rel="prefetch" href="/assets/js/16.7a3e1fe5.js"><link rel="prefetch" href="/assets/js/17.d6481ac8.js"><link rel="prefetch" href="/assets/js/18.4245937e.js"><link rel="prefetch" href="/assets/js/19.9bf7007f.js"><link rel="prefetch" href="/assets/js/20.f9ad486e.js"><link rel="prefetch" href="/assets/js/21.f12ae56b.js"><link rel="prefetch" href="/assets/js/22.cc92a370.js"><link rel="prefetch" href="/assets/js/24.b3fd754c.js"><link rel="prefetch" href="/assets/js/25.02d45b74.js"><link rel="prefetch" href="/assets/js/26.0a8fc004.js"><link rel="prefetch" href="/assets/js/27.27cc8c8e.js"><link rel="prefetch" href="/assets/js/28.9d729824.js"><link rel="prefetch" href="/assets/js/29.18ca49b9.js"><link rel="prefetch" href="/assets/js/30.bede3f7e.js"><link rel="prefetch" href="/assets/js/31.ea5a8413.js"><link rel="prefetch" href="/assets/js/32.b44d7022.js"><link rel="prefetch" href="/assets/js/33.797213ac.js"><link rel="prefetch" href="/assets/js/34.b169fd44.js"><link rel="prefetch" href="/assets/js/35.0381f5ba.js"><link rel="prefetch" href="/assets/js/36.1aa50c7d.js"><link rel="prefetch" href="/assets/js/37.272e3e3e.js"><link rel="prefetch" href="/assets/js/38.c248ace1.js"><link rel="prefetch" href="/assets/js/39.507a596f.js"><link rel="prefetch" href="/assets/js/4.09dda623.js"><link rel="prefetch" href="/assets/js/40.e3f806ec.js"><link rel="prefetch" href="/assets/js/41.7b2aefa4.js"><link rel="prefetch" href="/assets/js/42.7701b09f.js"><link rel="prefetch" href="/assets/js/43.d225b90a.js"><link rel="prefetch" href="/assets/js/44.e3c0ceb4.js"><link rel="prefetch" href="/assets/js/45.b8e57277.js"><link rel="prefetch" href="/assets/js/46.5e55dca6.js"><link rel="prefetch" href="/assets/js/47.27d140f5.js"><link rel="prefetch" href="/assets/js/48.3d8f06d2.js"><link rel="prefetch" href="/assets/js/5.9efeece9.js"><link rel="prefetch" href="/assets/js/6.45c24d02.js"><link rel="prefetch" href="/assets/js/7.3391c463.js"><link rel="prefetch" href="/assets/js/8.1d292254.js"><link rel="prefetch" href="/assets/js/9.49750083.js">
    <link rel="stylesheet" href="/assets/css/0.styles.c67cb200.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>KII IINE</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>明早一起去看海 望向未来</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>KII IINE</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2023
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/favicon.ico" alt="KII IINE" class="logo"> <span class="site-name">KII IINE</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CV/" class="nav-link"><i class="undefined"></i>
  CV
</a></li><li class="dropdown-item"><!----> <a href="/categories/深度学习/" class="nav-link"><i class="undefined"></i>
  深度学习
</a></li><li class="dropdown-item"><!----> <a href="/categories/闲言碎语/" class="nav-link"><i class="undefined"></i>
  闲言碎语
</a></li><li class="dropdown-item"><!----> <a href="/categories/Exp/" class="nav-link"><i class="undefined"></i>
  Exp
</a></li><li class="dropdown-item"><!----> <a href="/categories/Hadoop/" class="nav-link"><i class="undefined"></i>
  Hadoop
</a></li><li class="dropdown-item"><!----> <a href="/categories/thinks/" class="nav-link"><i class="undefined"></i>
  thinks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/funny/" class="nav-link"><i class="undefined"></i>
  funny
</a></li><li class="dropdown-item"><!----> <a href="/categories/Music/" class="nav-link"><i class="undefined"></i>
  Music
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/project/" class="nav-link"><i class="iconfont icon-project"></i>
  Project
</a></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kii-chan-iine/kii-chan-iine.github.io/tree/develop" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="mailto:kaichen1993@hotmail.com" class="nav-link external"><i class="iconfont icon-Gmail"></i>
  Mail
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/avatar.jpeg" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    KII IINE
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>31</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>12</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CV/" class="nav-link"><i class="undefined"></i>
  CV
</a></li><li class="dropdown-item"><!----> <a href="/categories/深度学习/" class="nav-link"><i class="undefined"></i>
  深度学习
</a></li><li class="dropdown-item"><!----> <a href="/categories/闲言碎语/" class="nav-link"><i class="undefined"></i>
  闲言碎语
</a></li><li class="dropdown-item"><!----> <a href="/categories/Exp/" class="nav-link"><i class="undefined"></i>
  Exp
</a></li><li class="dropdown-item"><!----> <a href="/categories/Hadoop/" class="nav-link"><i class="undefined"></i>
  Hadoop
</a></li><li class="dropdown-item"><!----> <a href="/categories/thinks/" class="nav-link"><i class="undefined"></i>
  thinks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/funny/" class="nav-link"><i class="undefined"></i>
  funny
</a></li><li class="dropdown-item"><!----> <a href="/categories/Music/" class="nav-link"><i class="undefined"></i>
  Music
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/project/" class="nav-link"><i class="iconfont icon-project"></i>
  Project
</a></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/kii-chan-iine/kii-chan-iine.github.io/tree/develop" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="mailto:kaichen1993@hotmail.com" class="nav-link external"><i class="iconfont icon-Gmail"></i>
  Mail
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Convolution</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>KII IINE</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2023
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">Convolution</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>kii</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>1/25/2022</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>deeplearn</span></i></div></div> <div class="theme-reco-content content__default"><div id="boxx" data-v-f4ca0dac><div data-v-f4ca0dac><p v-if="true" class="custom-block-title" data-v-f4ca0dac></p> <p v-if="true" data-v-f4ca0dac></p></div></div> <div class="custom-block tip"><p class="title">前言</p><p>深度学习中有各种卷积，不同的卷积的作用不一，这里汇总了一些常见的卷积类型。</p></div> <h1 id="各种卷积"><a href="#各种卷积" class="header-anchor">#</a> 各种卷积</h1> <p>如果你听说过深度学习中不同种类的卷积（比如 2D / 3D / 1x1 /转置/扩张（Atrous）/空间可分/深度可分/平展/分组/混洗分组卷积），并且搞不清楚它们究竟是什么意思，那么这篇文章就是为你写的，能帮你理解它们实际的工作方式。</p> <p>在这篇文章中，我会归纳总结深度学习中常用的几种卷积，并会试图用一种每个人都能理解的方式解释它们。除了本文之外，还有一些关于这一主题的好文章，请参看原文。</p> <p>希望本文能帮助你构建起对卷积的直观认知，并成为你研究或学习的有用参考。</p> <p><strong>卷积与互相关</strong></p> <p>在信号处理、图像处理和其它工程/科学领域，卷积都是一种使用广泛的技术。在深度学习领域，<a href="https://mp.weixin.qq.com/s/G92Jo8llnc-uArUVku5rfA" target="_blank" rel="noopener noreferrer">卷积神经网络<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>（CNN）这种模型架构就得名于这种技术。但是，深度学习领域的卷积本质上是信号/图像处理领域内的互相关（cross-correlation）。这两种操作之间存在细微的差别。</p> <p>无需太过深入细节，我们就能看到这个差别。在信号/图像处理领域，卷积的定义是：</p> <p>$$
(f*g)(t)=\int^{\infty}_{-\infty} f(\tau)g(t-\tau)d\tau
$$
其定义是两个函数中一个函数经过反转和位移后再相乘得到的积的积分。下面的可视化展示了这一思想：</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171107985.png" alt="image-20220124171107985"></p> <p><em>信号处理中的卷积。过滤器 g 经过反转，然后再沿水平轴滑动。在每一个位置，我们都计算 f 和反转后的 g 之间相交区域的面积。这个相交区域的面积就是特定位置出的卷积值。</em></p> <p>这里，函数 <strong>g 是过滤器</strong>。它被反转后再沿水平轴滑动。在每一个位置，我们都计算 f 和反转后的 g 之间相交区域的面积。这个相交区域的面积就是特定位置出的卷积值。</p> <p>另一方面，互相关是两个函数之间的滑动点积或滑动内积。互相关中的过滤器不经过反转，而是直接滑过函数 f。f 与 g 之间的交叉区域即是互相关。下图展示了卷积与互相关之间的差异。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171121114.png" alt="image-20220124171121114"></p> <p><em>信号处理中卷积与互相关之间的差异</em></p> <p>在深度学习中，卷积中的过滤器不经过反转。严格来说，这是互相关。我们本质上是执行逐元素乘法和加法。但在深度学习中，直接将其称之为卷积更加方便。这没什么问题，因为过滤器的权重是在训练阶段学习到的。如果上面例子中的反转函数 g 是正确的函数，那么经过训练后，学习得到的过滤器看起来就会像是反转后的函数 g。因此，在训练之前，没必要像在真正的卷积中那样首先反转过滤器。</p> <h2 id="一、2d卷积"><a href="#一、2d卷积" class="header-anchor">#</a> 一、2D卷积</h2> <p>在tensorflow中的conv2d中，</p> <p>input的四个维度是[batch, in_height, in_width, in_channels]，</p> <p>filter的四个维度是[filter_height, filter_width, in_channels, out_channels]。</p> <p>filter的<strong>通道数</strong>(深度)与<font color="red">输入层(前一层)的通道数(深度)是一致的</font>，就是in_channels！！！</p> <p>filter中out_channels数值 (输出通道数)= filter的数量/深度 = featuremap的数量</p> <p>对，就是 out_channels，有多少输出通道，就有多少个filter！！！</p> <h2 id="二、3d-卷积"><a href="#二、3d-卷积" class="header-anchor">#</a> <strong>二、3D 卷积</strong></h2> <p>在上一节的解释中，我们看到我们实际上是对一个 3D 体积执行卷积。但通常而言，我们仍在深度学习中称之为 <strong>2D 卷积</strong>。这<strong>是在 3D 体积数据上的 2D 卷积。过滤器深度与输入层深度一样。这个 3D 过滤器仅沿两个方向移动（图像的高和宽）。这种操作的输出是一张 2D 图像（仅有一个通道）。</strong>--就是上面的解释</p> <p>很自然，3D 卷积确实存在。这是 2D 卷积的泛化。下面就是 3D 卷积，其过<font color="red">滤器深度小于输入层深度</font>（核大小&lt;通道大小）。因此，**3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。**在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。</p> <blockquote><p>EC:我的理解是，像前面的普通卷积，输入是32*32*3的图像，如果卷积核的大小是3*3*1的，那么是不是也可以看做3D卷积呢？？</p></blockquote> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171132796.png" alt="image-20220124171132796"></p> <p><em>在 3D 卷积中，3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说<strong>输出是一个 3D 数据</strong>。</em></p> <p>与 2D 卷积（编码了 2D 域中目标的空间关系）类似，3D 卷积可以描述 3D 空间中目标的空间关系。对某些应用（比如<strong>生物医学影像</strong>中的 3D 分割/重构）而言，这样的 3D 关系很重要，比如在 CT 和 MRI 中，血管之类的目标会在 3D 空间中蜿蜒曲折。</p> <h2 id="三、转置卷积-去卷积-反卷积"><a href="#三、转置卷积-去卷积-反卷积" class="header-anchor">#</a> <strong>三、转置卷积（去卷积，反卷积）</strong></h2> <h3 id="场景"><a href="#场景" class="header-anchor">#</a> 场景：</h3> <ol><li><strong>生成高分辨率图像</strong></li> <li><strong>将低维特征图映射到高维空间</strong>，比如在<strong>自动编码器或形义分割中。</strong></li></ol> <p>对于很多网络架构的很多应用而言，我们往往需要进行与普通卷积方向相反的转换，即我们希望执行上采样。例子包括<strong>生成高分辨率图像</strong>以及<strong>将低维特征图映射到高维空间</strong>，比如在<strong>自动编码器或形义分割中。</strong>（在后者的例子中，形义分割首先会提取编码器中的特征图，然后在解码器中恢复原来的图像大小，使其可以分类原始图像中的每个像素。）</p> <p><font color="red">实现上采样的传统方法是应用插值方案或人工创建规则。而神经网络等现代架构则倾向于让网络自己自动学习合适的变换，无需人类干预。</font>为了做到这一点，我们可以使用<a href="https://mp.weixin.qq.com/s/G92Jo8llnc-uArUVku5rfA" target="_blank" rel="noopener noreferrer">转置卷积<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>转置卷积在文献中也被称为去卷积或 fractionally strided convolution。但是，需要指出「去卷积（deconvolution）」这个名称并不是很合适，因为转置卷积并非信号/图像处理领域定义的那种真正的去卷积。从技术上讲，信号处理中的去卷积是卷积运算的逆运算。但这里却不是这种运算。因此，某些作者强烈反对将转置卷积称为去卷积。人们称之为去卷积主要是因为这样说很简单。<strong>后面我们会介绍为什么将这种运算称为转置卷积更自然且更合适。</strong></p> <p>我们一直都可以使用直接的卷积实现转置卷积。对于下图的例子，我们在一个 2×2 的输入（周围加了 2×2 的单位步长的零填充）上应用一个 3×3 核的转置卷积。上采样输出的大小是 4×4。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171144473.png" alt="image-20220124171144473"></p> <p><em>将 2×2 的输入上采样成 4×4 的输出</em></p> <p>有趣的是，通过应用<font color="red">各种填充和步长</font>，我们可以将同样的 2×2 输入图像映射到不同的图像尺寸。下面，转置卷积被用在了同一张 2×2 输入上（输入之间插入了一个零，并且周围加了 2×2 的单位步长的零填充），所得输出的大小是 5×5。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171154305.png" alt="image-20220124171154305"></p> <p><em>将 2×2 的输入上采样成 5×5 的输出</em></p> <p>观察上述例子中的转置卷积能帮助我们构建起一些直观认识。但为了泛化其应用，了解其可以如何通过计算机的矩阵乘法实现是有益的。从这一点上我们也可以看到为何「转置卷积」才是合适的名称。</p> <p>在卷积中，我们定义 C 为卷积核，Large 为输入图像，Small 为输出图像。经过卷积（矩阵乘法）后，我们将大图像下采样为小图像。这种矩阵乘法的卷积的实现遵照：C x Large = Small。</p> <p>下面的例子展示了这种运算的工作方式。它将输入平展为 16×1 的矩阵，并将卷积核转换为一个稀疏矩阵（4×16）。然后，在稀疏矩阵和平展的输入之间使用矩阵乘法。之后，再将所得到的矩阵（4×1）转换为 2×2 的输出。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171243429.png" alt="image-20220124171243429"></p> <p>​                                                                                 <em>卷积的矩阵乘法：将 Large 输入图像（4×4）转换为 Small 输出图像（2×2）</em></p> <p>现在，如果我们在等式的两边都乘上矩阵的转置 CT，并借助「一个矩阵与其转置矩阵的乘法得到一个单位矩阵」这一性质，那么我们就能得到公式 CT x Small = Large，如下图所示。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171258338.png" alt="image-20220124171258338"></p> <p>​																<em>卷积的矩阵乘法：将 Small 输入图像（2×2）转换为 Large 输出图像（4×4）</em></p> <p>这里可以看到，我们执行了从小图像到大图像的上采样。这正是我们想要实现的目标。现在。你就知道「转置卷积」这个名字的由来了。</p> <p>转置矩阵的算术解释可参阅：https://arxiv.org/abs/1603.07285</p> <h2 id="四、-空洞-扩张卷积-atrous-卷积"><a href="#四、-空洞-扩张卷积-atrous-卷积" class="header-anchor">#</a> <strong>四、（空洞）扩张卷积（Atrous 卷积）</strong></h2> <p><strong>当网络层需要较大的感受野，但计算资源有限而无法提高卷积核数量或大小时，可以考虑空洞卷积</strong></p> <p>扩张卷积由这两篇引入：</p> <ul><li>https://arxiv.org/abs/1412.7062；</li> <li>https://arxiv.org/abs/1511.07122</li></ul> <p>这是一个标准的离散卷积：</p> <p>$$
(F\ast k)(p)=\sum_{s+t=p}F(s)K(t)
$$
<img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20210823231144207.png" alt="image-20210823231144207"></p> <p>扩张卷积如下：</p> <p>$$
(F\ast <em>l k)(p)=\sum</em>{s+lt=p}F(s)K(t)
$$</p> <p>当 l=1 时，扩张卷积会变得和标准卷积一样。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171333481.png" alt="image-20220124171333481"></p> <p><em>扩张卷积</em></p> <p>直观而言，<strong>扩张卷积就是通过在核元素之间插入空格来使核「膨胀」</strong>。新增的参数 l（扩张率）表示我们希望将核加宽的程度。具体实现可能各不相同，但通常是在核元素之间插入 <strong>l-1 个空格</strong>。下面展示了 l = 1, 2, 4 时的核大小。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171345649.png" alt="image-20220124171345649"></p> <p><em>扩张卷积的感受野。我们基本上无需添加额外的成本就能有较大的感受野。</em></p> <p>在这张图像中，3×3 的红点表示经过卷积后，输出图像是 3×3 像素。<font color="red">尽管所有这三个扩张卷积的输出都是同一尺寸，但模型观察到的感受野有很大的不同。</font>l=1 时感受野为 3×3，l=2 时为 7×7。l=3 时，感受野的大小就增加到了 15×15。有趣的是，与这些操作相关的参数的数量是相等的。我们「观察」更大的感受野不会有额外的成本。因此，扩张卷积可用于<strong>廉价地增大输出单元的感受野，而不会增大其核大小，这在多个扩张卷积彼此堆叠时尤其有效</strong>。</p> <p>论文《Multi-scale context aggregation by dilated convolutions》的作者用多个扩张卷积层构建了一个网络，其中扩张率 l 每层都按指数增大。由此，有效的感受野大小随层而指数增长，而参数的数量仅线性增长。</p> <p>这篇论文中扩张卷积的作用是系统性地聚合多个比例的形境信息，而不丢失分辨率。这篇论文表明其提出的模块能够提升那时候（2016 年）的当前最佳形义分割系统的准确度。请参阅那篇论文了解更多信息。</p> <h3 id="存在的问题"><a href="#存在的问题" class="header-anchor">#</a> <strong>存在的问题</strong></h3> <p>扩张卷积虽然在不损失特征图尺寸的情况下增大了感受野，但是也会带来新的问题，主要是体现在卷积的输入，<strong>由于卷积核是有间隔的，这意味着不是所有的输入都参与计算，整体特征图上体现出一种卷积中心点的不连续</strong>，尤其是当叠加的卷积层都是用相同的dilation rate的时候：</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171403130.png" alt="image-20220124171403130"></p> <p>上图中示例是三个dilation rate=2扩张卷积层连续卷积后的结果，蓝色的标识是参与计算的卷积中心，而颜色的深度表征次数。可以看到，由于3次的dilation rate是一致的，所以卷积的计算中心会呈现出一种网格状向外扩展，有一些点不会成为计算的中心点。</p> <h3 id="解决方法"><a href="#解决方法" class="header-anchor">#</a> <strong>解决方法</strong></h3> <p>解决这个问题最直接的方法当然就是不使用连续的dilation rate相同的扩展卷积，但是这还不够，因为如果dilation rate是成倍数的，那么问题还是存在。<strong>所以最好的方式是将连续排布的扩张卷积的dilation rate设置为“锯齿状”，比如分别是[1，2，3]</strong>，那么卷积中心的分布就会变成下面这样，不在有遗漏的情况。</p> <p><img src="%E5%90%84%E7%A7%8D%E5%8D%B7%E7%A7%AF%20a7f644dc9a9940bf8eded1aa7c649dbb/Untitled.png" alt="%E5%90%84%E7%A7%8D%E5%8D%B7%E7%A7%AF%20a7f644dc9a9940bf8eded1aa7c649dbb/Untitled.png"></p> <h2 id="五、可分卷积"><a href="#五、可分卷积" class="header-anchor">#</a> <strong>五、可分卷积</strong></h2> <p>某些神经网络架构使用了可分卷积，比如 <a href="https://mp.weixin.qq.com/s/G92Jo8llnc-uArUVku5rfA" target="_blank" rel="noopener noreferrer">MobileNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。可分卷积有空间可分卷积和深度可分卷积。(<strong>可减少计算量</strong>)</p> <h3 id="_1、空间可分卷积"><a href="#_1、空间可分卷积" class="header-anchor">#</a> <strong>1、空间可分卷积</strong></h3> <p>空间可分卷积操作的是图像的 2D 空间维度，即高和宽。从概念上看，空间可分卷积是将一个卷积分解为两个单独的运算。对于下面的示例，3×3 的 Sobel 核被分成了一个 3×1 核和一个 1×3 核。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171421527.png" alt="image-20220124171421527"></p> <p><em>Sobel 核可分为一个 3x1 和一个 1x3 核</em></p> <p>在卷积中，3×3 核直接与图像卷积。在空间可分卷积中，3×1 核首先与图像卷积，然后再应用 1×3 核。这样，执行同样的操作时仅需 6 个参数，而不是 9 个。</p> <p>此外，使用空间可分卷积时所需的矩阵乘法也更少。给一个具体的例子，5×5 图像与 3×3 核的卷积（步幅=1，填充=0）要求在 3 个位置水平地扫描核（还有 3 个垂直的位置）。总共就是 9 个位置，表示为下图中的点。在每个位置，会应用 9 次逐元素乘法。总共就是 9×9=81 次乘法。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171440313.png" alt="image-20220124171440313"></p> <p><em>具有 1 个通道的标准卷积</em></p> <p>另一方面，对于空间可分卷积，我们首先在 5×5 的图像上应用一个 3×1 的过滤器。我们可以在水平 5 个位置和垂直 3 个位置扫描这样的核。总共就是 5×3=15 个位置，表示为下图中的点。在每个位置，会应用 3 次逐元素乘法。总共就是 15×3=45 次乘法。现在我们得到了一个 3×5 的矩阵。这个矩阵再与一个 1×3 核卷积，即在水平 3 个位置和垂直 3 个位置扫描这个矩阵。对于这 9 个位置中的每一个，应用 3 次逐元素乘法。这一步需要 9×3=27 次乘法。因此，总体而言，空间可分卷积需要 45+27=72 次乘法，少于普通卷积。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171452576.png" alt="image-20220124171452576"></p> <p><em>具有 1 个通道的空间可分卷积</em></p> <p>我们稍微推广一下上面的例子。假设我们现在将卷积应用于一张 N×N 的图像上，卷积核为 m×m，步幅为 1，填充为 0。传统卷积需要 (N-m+1) x (N-m+1) x m x m 次乘法，空间可分卷积需要 N x (N-m+1) x m + (N-m+1) x (N-m+1) x m = (2N-m+1) x (N-m+1) x m 次乘法。空间可分卷积与标准卷积的计算成本比为：(原文是错的)—<strong>下面的公式可能错的，看得时候注意</strong>
$$
\frac{2}{m}+\frac{2}{m(N-2)}
$$</p> <p>因为图像尺寸 N 远大于过滤器大小（N&gt;&gt;m），所以这个比就变成了 2/m。也就是说，在这种渐进情况（N&gt;&gt;m）下，当过滤器大小为 3×3 时，空间可分卷积的计算成本是标准卷积的 2/3。过滤器大小为 5×5 时这一数值是 2/5；过滤器大小为 7×7 时则为 2/7。</p> <p>尽管空间可分卷积能节省成本，<strong>但深度学习却很少使用它</strong>。一大主要原因是并非所有的核都能分成两个更小的核。如果我们用空间可分卷积替代所有的传统卷积，那么我们就限制了自己在训练过程中搜索所有可能的核。这样得到的训练结果可能是次优的。</p> <h3 id="_2、深度可分卷积"><a href="#_2、深度可分卷积" class="header-anchor">#</a> <strong>2、深度可分卷积</strong></h3> <p>现在来看深度可分卷积，这在深度学习领域要常用得多（比如 MobileNet 和 Xception）。深度可分卷积包含两个步骤：深度卷积 和 1×1 卷积。</p> <p>在描述这些步骤之前，有必要回顾一下我们之前介绍的 2D 卷积核 1×1 卷积。首先快速回顾标准的 2D 卷积。举一个具体例子，假设输入层的大小是 7×7×3（高×宽×通道），而过滤器的大小是 3×3×3。经过与一个过滤器的 2D 卷积之后，输出层的大小是 5×5×1（仅有一个通道）。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171553990.png" alt="image-20220124171553990"></p> <p>​																								<font color="blue"><em>用于创建仅有 1 层的输出的标准 2D 卷积，使用 1 个过滤器</em></font></p> <p>一般来说，两个神经网络层之间会应用多个过滤器。假设我们这里有 128 个过滤器(<font color="red">卷积核</font>)。在应用了这 128 个 2D 卷积之后，我们有 128 个 5×5×1 的输出映射图（map）。然后我们将这些映射图堆叠成大小为 5×5×128 的单层。通过这种操作，我们可将输入层（7×7×3）转换成输出层（5×5×128）。空间维度（即高度和宽度）会变小，而深度会增大。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171607336.png" alt="image-20220124171607336"></p> <p>​																						<em>用于创建有 128 层的输出的标准 2D 卷积，要使用 128 个过滤器</em></p> <hr> <p>现在使用深度可分卷积，看看我们如何实现同样的变换。</p> <p>首先，我们将深度卷积应用于输入层。但我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。现在我们可以降低空间维度了，但深度还是和之前一样。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171619136.png" alt="image-20220124171619136"></p> <p>深度可分卷积——<font color="magenta">第一步</font>：我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。</p> <p>在深度可分卷积的<font color="magenta">第二步</font>，为了扩展深度，我们应用一个核大小为 1×1×3 的 1×1 卷积。将 5×5×3 的输入图像与每个 1×1×3 的核卷积，可得到大小为 5×5×1 的映射图。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171631497.png" alt="image-20220124171631497"></p> <p>因此，在应用了 128 个 1×1 卷积之后，我们得到大小为 5×5×128 的层。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171648383.png" alt="image-20220124171648383"></p> <p>​																			<em>figure：深度可分卷积——第二步：应用多个 1×1 卷积来修改深度。</em></p> <p>通过这两个步骤，深度可分卷积也会将输入层（7×7×3）变换到输出层（5×5×128）。</p> <p>下图展示了深度可分卷积的整个过程。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171701828.png" alt="image-20220124171701828"></p> <p>​																											<em>figure: 深度可分卷积的整个过程</em></p> <p>所以，深度可分卷积有何优势呢？效率！相比于 2D 卷积，深度可分卷积所需的操作要少得多。</p> <p>回忆一下我们的 2D 卷积例子的计算成本。有 128 个 3×3×3 个核移动了 5×5 次，也就是 128 x 3 x 3 x 3 x 5 x 5 = 86400 次乘法。</p> <p>可分卷积又如何呢？在第一个深度卷积步骤，有 3 个 3×3×1 核移动 5×5 次，也就是 3x3x3x1x5x5 = 675 次乘法。在 1×1 卷积的第二步，有 128 个 1×1×3 核移动 5×5 次，即 128 x 1 x 1 x 3 x 5 x 5 = 9600 次乘法。因此，深度可分卷积共有 675 + 9600 = 10275 次乘法。这样的成本大概仅有 2D 卷积的 12%！</p> <p>所以，对于任意尺寸的图像，如果我们应用深度可分卷积，我们可以节省多少时间？让我们泛化以上例子。现在，对于大小为 H×W×D 的输入图像，如果使用 Nc 个大小为 h×h×D 的核执行 2D 卷积（步幅为 1，填充为 0，其中 h 是偶数）。为了将输入层（H×W×D）变换到输出层（(H-h+1)x (W-h+1) x Nc），所需的总乘法次数为：</p> <p><strong>Nc x h x h x D x (H-h+1) x (W-h+1)</strong></p> <p>另一方面，对于同样的变换，深度可分卷积所需的乘法次数为：</p> <p><strong>D x h x h x 1 x (H-h+1) x (W-h+1) + Nc x 1 x 1 x D x (H-h+1) x (W-h+1) = (h x h + Nc) x D x (H-h+1) x (W-h+1)</strong></p> <p>则深度可分卷积与 2D 卷积所需的乘法次数比为：</p> <p>$$
\frac{1}{N_c}+\frac{1}{h^2}
$$</p> <p>现代大多数架构的输出层通常都有很多通道，可达数百甚至上千。对于这样的层（$N_c &gt;&gt; h$），则上式可约简为 1 / h²。基于此，如果使用 3×3 过滤器，则 2D 卷积所需的乘法次数是深度可分卷积的 9 倍。如果使用 5×5 过滤器，则 2D 卷积所需的乘法次数是深度可分卷积的 25 倍。</p> <h3 id="优点"><a href="#优点" class="header-anchor">#</a> 优点</h3> <p>效率</p> <h3 id="缺点"><a href="#缺点" class="header-anchor">#</a> 缺点</h3> <p>使用深度可分卷积有什么坏处吗？当然是有的。<strong>深度可分卷积会降低卷积中参数的数量</strong>。因此，对于较小的模型而言，如果用深度可分卷积替代 2D 卷积，模型的能力可能会显著下降。因此，得到的模型可能是次优的。但是，如果使用得当，深度可分卷积能在不降低你的模型性能的前提下帮助你实现效率提升。</p> <h2 id="六、分组卷积"><a href="#六、分组卷积" class="header-anchor">#</a> <strong>六、分组卷积</strong></h2> <p>AlexNet 论文（https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf）在 2012 年引入了分组卷积。实现分组卷积的主要原因是让网络训练可在 2 个内存有限（每个 GPU 有 1.5 GB 内存）的 GPU 上进行。下面的 AlexNet 表明在大多数层中都有两个分开的卷积路径。这是在两个 GPU 上执行模型并行化（当然如果可以使用更多 GPU，还能执行多 GPU 并行化）。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171715954.png" alt="image-20220124171715954"></p> <p>​																													<em>图片来自 AlexNet 论文</em></p> <p>这里我们介绍一下分组卷积的工作方式。首先，典型的 2D 卷积的步骤如下图所示。在这个例子中，通过应用 128 个大小为 3×3×3 的过滤器将输入层（7×7×3）变换到输出层（5×5×128）。推广而言，即通过应用 Dout 个大小为 h x w x Din 的核将输入层（Hin x Win x Din）变换到输出层（Hout x Wout x Dout）。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171733195.png" alt="image-20220124171733195"></p> <p>​																												figure. <em>标准的 2D 卷积</em></p> <p>在分组卷积中，过滤器会被分为不同的组。每一组都负责特定深度的典型 2D 卷积。下面的例子能让你更清楚地理解。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171747092.png" alt="image-20220124171747092"></p> <p>​																																<em>具有两个过滤器分组的分组卷积</em></p> <p>上图展示了具有两个过滤器分组的分组卷积。在每个过滤器分组中，每个过滤器的深度仅有名义上的 2D 卷积的一半。它们的深度是 Din/2。每个过滤器分组包含 Dout/2 个过滤器。第一个过滤器分组（红色）与输入层的前一半（[:, :, 0:Din/2]）卷积，而第二个过滤器分组（橙色）与输入层的后一半（[:, :, Din/2:Din]）卷积。因此，每个过滤器分组都会创建 Dout/2 个通道。整体而言，两个分组会创建 2×Dout/2 = Dout 个通道。然后我们将这些通道堆叠在一起，得到有 Dout 个通道的输出层。</p> <p><strong>1、分组卷积与深度卷积</strong></p> <p>你可能会注意到分组卷积与深度可分卷积中使用的深度卷积之间存在一些联系和差异。<strong>如果过滤器分组的数量与输入层通道的数量相同</strong>，则每个过滤器的深度都为 Din/Din=1。这样的过滤器深度就与深度卷积中的一样了。</p> <p>另一方面，现在每个过滤器分组都包含 Dout/Din 个过滤器。整体而言，输出层的深度为 Dout。这不同于深度卷积的情况——深度卷积并不会改变层的深度。在深度可分卷积中，层的深度之后通过 1×1 卷积进行扩展。</p> <h3 id="优点-2"><a href="#优点-2" class="header-anchor">#</a> 优点</h3> <p><strong>第一个优点是高效训练</strong>。因为卷积被分成了多个路径，每个路径都可由不同的 GPU 分开处理，所以模型可以并行方式在多个 GPU 上进行训练。相比于在单个 GPU 上完成所有任务，这样的在多个 GPU 上的模型并行化能让网络在每个步骤处理更多图像。人们一般认为模型并行化比数据并行化更好。后者是将数据集分成多个批次，然后分开训练每一批。但是，当批量大小变得过小时，我们本质上是执行随机梯度下降，而非批梯度下降。这会造成更慢，有时候更差的收敛结果。</p> <p>在训练非常深的神经网络时，分组卷积会非常重要，正如在 ResNeXt 中那样。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171759215.png" alt="image-20220124171759215"></p> <p><em>图片来自 ResNeXt 论文，https://arxiv.org/abs/1611.05431</em></p> <p>**第二个优点是模型会更高效，即模型参数会随过滤器分组数的增大而减少。**在之前的例子中，完整的标准 2D 卷积有 h x w x Din x Dout 个参数。具有 2 个过滤器分组的分组卷积有 (h x w x Din/2 x Dout/2) x 2 个参数。参数数量减少了一半。</p> <p>**第三个优点有些让人惊讶。分组卷积也许能提供比标准完整 2D 卷积更好的模型。**另一篇出色的博客已经解释了这一点：https://blog.yani.io/filter-group-tutorial。这里简要总结一下。</p> <p>原因和稀疏过滤器的关系有关。下图是相邻层过滤器的相关性。其中的关系是稀疏的。</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171814592.png" alt="image-20220124171814592"></p> <p><em>在 CIFAR10 上训练的一个 Network-in-Network 模型中相邻层的过滤器的相关性矩阵。高度相关的过滤器对更明亮，而相关性更低的过滤器则更暗。图片来自：https://blog.yani.io/filter-group-tutorial</em></p> <p>分组矩阵的相关性映射图又如何？</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171828658.png" alt="image-20220124171828658"></p> <p><em>在 CIFAR10 上训练的一个 Network-in-Network 模型中相邻层的过滤器的相关性，动图分别展示了有 1、2、4、8、16 个过滤器分组的情况。图片来自 https://blog.yani.io/filter-group-tutorial</em></p> <p>上图是当用 1、2、4、8、16 个过滤器分组训练模型时，相邻层的过滤器之间的相关性。那篇文章提出了一个推理：「过滤器分组的效果是在<strong>通道维度上学习块对角结构的稀疏性</strong>……<strong>在网络中，具有高相关性的过滤器是使用过滤器分组以一种更为结构化的方式学习到</strong>。从效果上看，不必学习的过滤器关系就不再参数化。这样显著地减少网络中的参数数量能使其不容易过拟合，因此，一种类似正则化的效果让优化器可以学习得到更准确更高效的深度网络。」</p> <p><img src="https://imagerk.oss-cn-beijing.aliyuncs.com/img/image-20220124171839839.png" alt="image-20220124171839839"></p> <p><em>AlexNet conv1 过滤器分解：正如作者指出的那样，过滤器分组似乎会将学习到的过滤器结构性地组织成两个不同的分组。本图来自 AlexNet 论文。</em></p> <p>此外，每个过滤器分组都会学习数据的一个独特表征。正如 AlexNet 的作者指出的那样，过滤器分组似乎会将学习到的过滤器结构性地组织成两个不同的分组——黑白过滤器和彩色过滤器。</p> <p>你认为深度学习领域的卷积还有那些值得注意的地方？</p> <p><em>原文链接：https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215</em></p> <h2 id="七、1-times-1卷积"><a href="#七、1-times-1卷积" class="header-anchor">#</a> 七、1$\times$1卷积</h2> <p>作用：</p> <ol><li>跨通道的特征整合</li> <li>特征通道的升维和降维</li> <li>加非线性</li> <li>减少卷积核参数（简化模型），减少计算量</li> <li>跨通道信息交互(channal变换)</li></ol> <h3 id="跨通道的特征整合"><a href="#跨通道的特征整合" class="header-anchor">#</a> 跨通道的特征整合</h3> <p>如果当前层和下一层都只有一个通道那么1×1卷积核确实没什么作用，但是如果它们分别为m层和n层的话，1×1卷积核可以起到一个跨通道聚合的作用，所以进一步可以起到降维（或者升维）的作用，起到减少参数的目的。</p> <h3 id="升维和降维"><a href="#升维和降维" class="header-anchor">#</a> 升维和降维</h3> <h3 id="加非线性"><a href="#加非线性" class="header-anchor">#</a> 加非线性</h3> <p>1*1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很deep。</p> <p>备注：一个filter对应卷积后得到一个feature map，不同的filter(不同的weight和bias)，卷积以后得到不同的feature map，提取不同的特征，得到对应的specialized neuron。</p> <h3 id="减少卷积核参数-简化模型-减少计算量"><a href="#减少卷积核参数-简化模型-减少计算量" class="header-anchor">#</a> 减少卷积核参数（简化模型），减少计算量</h3> <h3 id="跨通道信息交互-channal变换"><a href="#跨通道信息交互-channal变换" class="header-anchor">#</a> 跨通道信息交互(channal变换)</h3> <h3 id="应用"><a href="#应用" class="header-anchor">#</a> 应用</h3> <p>Resnet-bottleneck</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">a year ago</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#一、2d卷积" class="sidebar-link reco-side-一、2d卷积" data-v-70334359>一、2D卷积</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#二、3d-卷积" class="sidebar-link reco-side-二、3d-卷积" data-v-70334359>二、3D 卷积</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#三、转置卷积-去卷积-反卷积" class="sidebar-link reco-side-三、转置卷积-去卷积-反卷积" data-v-70334359>三、转置卷积（去卷积，反卷积）</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#场景" class="sidebar-link reco-side-场景" data-v-70334359>场景：</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#四、-空洞-扩张卷积-atrous-卷积" class="sidebar-link reco-side-四、-空洞-扩张卷积-atrous-卷积" data-v-70334359>四、（空洞）扩张卷积（Atrous 卷积）</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#存在的问题" class="sidebar-link reco-side-存在的问题" data-v-70334359>存在的问题</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#解决方法" class="sidebar-link reco-side-解决方法" data-v-70334359>解决方法</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#五、可分卷积" class="sidebar-link reco-side-五、可分卷积" data-v-70334359>五、可分卷积</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#_1、空间可分卷积" class="sidebar-link reco-side-_1、空间可分卷积" data-v-70334359>1、空间可分卷积</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#_2、深度可分卷积" class="sidebar-link reco-side-_2、深度可分卷积" data-v-70334359>2、深度可分卷积</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#优点" class="sidebar-link reco-side-优点" data-v-70334359>优点</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#缺点" class="sidebar-link reco-side-缺点" data-v-70334359>缺点</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#六、分组卷积" class="sidebar-link reco-side-六、分组卷积" data-v-70334359>六、分组卷积</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#优点-2" class="sidebar-link reco-side-优点-2" data-v-70334359>优点</a></li><li class="level-2" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#七、1-times-1卷积" class="sidebar-link reco-side-七、1-times-1卷积" data-v-70334359>七、1$\times$1卷积</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#跨通道的特征整合" class="sidebar-link reco-side-跨通道的特征整合" data-v-70334359>跨通道的特征整合</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#升维和降维" class="sidebar-link reco-side-升维和降维" data-v-70334359>升维和降维</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#加非线性" class="sidebar-link reco-side-加非线性" data-v-70334359>加非线性</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#减少卷积核参数-简化模型-减少计算量" class="sidebar-link reco-side-减少卷积核参数-简化模型-减少计算量" data-v-70334359>减少卷积核参数（简化模型），减少计算量</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#跨通道信息交互-channal变换" class="sidebar-link reco-side-跨通道信息交互-channal变换" data-v-70334359>跨通道信息交互(channal变换)</a></li><li class="level-3" data-v-70334359><a href="/views/Deeplearn/Different_conv.html#应用" class="sidebar-link reco-side-应用" data-v-70334359>应用</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><canvas id="vuepress-canvas-cursor"></canvas><!----><div class="vuepress-canvas-nest-element"></div><div class="kanbanniang" data-v-27e9bfa4><div class="banniang-container" style="display:;" data-v-27e9bfa4><div class="messageBox" style="position:fixed;right:75px;bottom:235px;opacity:0.75;height:max-content;width:200px;fon-szie:16px;display:none;" data-v-27e9bfa4></div> <div class="operation" style="display:;" data-v-27e9bfa4><i data-v-27e9bfa4><svg t="1572660425629" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6044" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M577.5584 307.848533l-21.345067-18.699733c-0.062933-0.061867-0.186667-0.123733-0.280533-0.186667l-44.305067-38.689067-53.752533 47.5648L127.009067 587.424l0 177.1392 0 155.0048c0 45.886933 37.454933 83.0976 83.610667 83.0976l183.966933 0L394.586667 735.8688c0-27.512533 22.448-49.8336 50.162133-49.8336l133.7728 0c27.714133 0 50.178133 22.321067 50.178133 49.8336L628.699733 1002.666667l183.966933 0c46.170667 0 83.610667-37.211733 83.610667-83.0976L896.277333 763.9424 896.277333 586.7712 578.5216 308.688 577.5584 307.848533z" p-id="6045" data-v-27e9bfa4></path> <path d="M990.637867 418.164267l-94.360533-82.600533 0-181.290667c0-36.714667-29.952-66.482133-66.894933-66.482133-36.941867 0-66.893867 29.767467-66.893867 66.482133l0 64.197333L556.213333 37.911467c-25.291733-22.103467-63.165867-22.103467-88.4256 0L33.348267 418.164267c-27.730133 24.247467-30.402133 66.264533-5.9808 93.808 24.437333 27.544533 66.692267 30.219733 94.407467 5.938133L512 176.376533l390.2432 341.533867c12.7072 11.130667 28.4608 16.600533 44.181333 16.600533 18.549333 0 37.0048-7.617067 50.209067-22.538667C1021.054933 484.4128 1018.382933 442.4128 990.637867 418.164267z" p-id="6046" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660394444" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5299" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M0 202.7V631c0 83.3 68.3 150.7 152.6 150.7h228.9l8 190.3 224.9-190.3h257c84.3 0 152.6-67.4 152.6-150.7V202.7C1024 119.4 955.7 52 871.4 52H152.6C68.3 52 0 119.4 0 202.7z m658.6 237.9c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S771 512 730.9 512c-40.2 0-72.3-31.7-72.3-71.4z m-220.9 0c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S550.1 512 510 512c-40.2 0-72.3-31.7-72.3-71.4z m-216.8 0c0-39.7 32.1-71.4 72.3-71.4 40.2 0 72.3 31.7 72.3 71.4S333.3 512 293.1 512c-40.1 0-72.2-31.7-72.2-71.4z" p-id="5300" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660570409" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2153" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 393.846154c-86.646154 0-157.538462 70.892308-157.538462 157.538461s70.892308 157.538462 157.538462 157.538462 157.538462-70.892308 157.538462-157.538462-70.892308-157.538462-157.538462-157.538461z m393.846154-118.153846h-102.4c-27.569231 0-51.2-13.784615-66.953846-35.446154l-45.292308-68.923077C677.415385 137.846154 643.938462 118.153846 608.492308 118.153846h-192.984616c-35.446154 0-68.923077 19.692308-84.676923 53.169231l-45.292307 68.923077c-13.784615 21.661538-39.384615 35.446154-66.953847 35.446154H118.153846c-43.323077 0-78.769231 35.446154-78.769231 78.76923v472.615385c0 43.323077 35.446154 78.769231 78.769231 78.769231h787.692308c43.323077 0 78.769231-35.446154 78.769231-78.769231V354.461538c0-43.323077-35.446154-78.769231-78.769231-78.76923zM512 787.692308c-129.969231 0-236.307692-106.338462-236.307692-236.307693s106.338462-236.307692 236.307692-236.307692 236.307692 106.338462 236.307692 236.307692-106.338462 236.307692-236.307692 236.307693z" p-id="2154" data-v-27e9bfa4></path></svg></i> <i data-v-27e9bfa4><svg t="1572660469241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6553" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M706.544835 64.021106h-6.500041a159.889547 159.889547 0 0 0-83.558068 23.557532c-54.583153 33.422204-86.949304 40.439014-104.486726 40.439014-17.538445 0-49.903573-7.016811-104.494912-40.445154a159.88136 159.88136 0 0 0-83.550905-23.551392h-6.507204a127.823224 127.823224 0 0 0-97.182366 44.702108l-172.836417 201.635323c-19.522636 22.774703-20.600177 56.050574-2.609431 80.047104l95.995331 127.994116a63.99757 63.99757 0 0 0 83.198887 17.024745v328.558038c0 52.93256 43.060725 95.995331 95.995331 95.995331h415.98011c52.934606 0 95.995331-43.062771 95.995331-95.995331V535.424502a64.028269 64.028269 0 0 0 42.240033 7.749498 64.013943 64.013943 0 0 0 46.990221-34.528398l63.996546-127.856993c11.522428-23.027459 8.125051-50.721195-8.632611-70.278623L803.743574 108.74675c-24.335245-28.421306-59.770292-44.725644-97.198739-44.725644z" p-id="6554" data-v-27e9bfa4></path></svg></i>
      <a target="_blank" href="https://github.com/kii-chan-iine" data-v-27e9bfa4><i data-v-27e9bfa4><svg t="1572660325062" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3809" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 3.413333c280.849067 0 508.586667 199.273813 508.586667 444.94848 0 140.427947-74.519893 265.53344-190.65856 347.11552V1020.586667l-222.839467-135.168c-30.859947 5.147307-62.552747 8.021333-95.085227 8.021333-280.845653 0-508.586667-199.28064-508.586666-445.078187C3.413333 202.687147 231.150933 3.413333 512 3.413333z m-158.96576 603.921067h317.805227c17.578667 0 31.812267-14.2336 31.812266-31.819093a31.798613 31.798613 0 0 0-31.812266-31.80544h-317.805227c-17.578667 0-31.812267 14.2336-31.812267 31.80544 0.116053 17.585493 14.349653 31.819093 31.812267 31.819093z m-63.511893-190.665387h444.951893c17.578667 0 31.812267-14.2336 31.812267-31.812266a31.802027 31.802027 0 0 0-31.812267-31.81568H289.522347a31.802027 31.802027 0 0 0-31.81568 31.81568c0 17.578667 14.2336 31.812267 31.81568 31.812266z" p-id="3810" data-v-27e9bfa4></path></svg></i></a> <i data-v-27e9bfa4><svg t="1572660347392" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4543" width="16" height="16" class="icon" data-v-27e9bfa4><path d="M512 34.133333a486.4 486.4 0 1 0 486.4 486.4A486.4 486.4 0 0 0 512 34.133333z m209.4848 632.8064l-55.6032 55.466667-151.517867-151.125333-151.517866 151.1168-55.6032-55.466667 151.517866-151.108267L307.242667 364.714667l55.6032-55.466667 151.517866 151.125333 151.517867-151.1168 55.6032 55.466667-151.517867 151.099733z m0 0" p-id="4544" data-v-27e9bfa4></path></svg></i></div> <canvas id="banniang" width="216" height="281.6" class="live2d" style="position:fixed;right:90px;bottom:-20px;opacity:1;" data-v-27e9bfa4></canvas></div> <div class="showBanNiang" style="display:none;" data-v-27e9bfa4>
    看板娘
  </div></div><!----><div></div></div></div>
    <script src="/assets/js/app.65da1296.js" defer></script><script src="/assets/js/3.a67abeb3.js" defer></script><script src="/assets/js/1.c373aa88.js" defer></script><script src="/assets/js/23.d272b7b0.js" defer></script><script src="/assets/js/11.747f0d2b.js" defer></script>
  </body>
</html>
